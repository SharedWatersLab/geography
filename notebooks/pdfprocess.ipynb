{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting excel process for selena\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import pwd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from geography.classes.UserClass import UserClass\n",
    "from geography.classes.LoginClass import PasswordManager, WebDriverManager, Login\n",
    "from geography.classes.NoLinkClass import NoLinkClass\n",
    "from geography.classes.DownloadClass import Download\n",
    "\n",
    "basin_code = \"gron\"\n",
    "master_user = \"selena\"\n",
    "download_type = \"excel\"\n",
    "\n",
    "currentUser = UserClass(basin_code, master_user, download_type)\n",
    "currentUser.getName()\n",
    "paths = currentUser.getPath(download_type)\n",
    "\n",
    "\n",
    "#UPDATE USER CLASS WITH THESE\n",
    "\n",
    "user_name = paths[\"user_name\"]\n",
    "geography_folder = paths[\"geography_folder\"]\n",
    "download_folder_temp = paths[\"download_folder_temp\"]\n",
    "download_folder = paths[\"download_folder\"]\n",
    "status_file = paths[\"status_file\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password set!\n",
      "User is not logged in. Proceeding with login...\n",
      "need to go back through library login\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "\n",
    "    pm = PasswordManager()\n",
    "    if pm.password is None:\n",
    "        password = pm.get_password()\n",
    "        print(\"Password set!\")\n",
    "    else: pass\n",
    "        \n",
    "    manager = WebDriverManager()\n",
    "    #options = manager.setup_options()\n",
    "    driver = manager.start_driver()\n",
    "\n",
    "    time.sleep(5)\n",
    "    login = Login(user_name=user_name, password=password, driver_manager=manager, url=None)\n",
    "        \n",
    "    login._init_login()\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already on Nexis Uni home page\n",
      "Initializing search for gron\n",
      "had to click search button again for some reason\n"
     ]
    }
   ],
   "source": [
    "computer_name = pwd.getpwuid(os.getuid()).pw_name\n",
    "base_path = f'/Users/{computer_name}'\n",
    "# this part here ^ doesn't exist in userclass but I'd like to add it\n",
    "\n",
    "nlc = NoLinkClass(driver, basin_code, download_type, base_path)\n",
    "nlc._search_process()\n",
    "time.sleep(10)\n",
    "\n",
    "# sometimes there's an error on clicking the search_button in complete_search method\n",
    "# I changed it to an xpath from css... the next thing to try if the issue recurs is a check and click again\n",
    "# it could also be an issue of not sleeping enough time after sending search terms\n",
    "\n",
    "#nlc.complete_search() # because if I run this separately it clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# when all this stuff is greyed out, does this mean I'm not using it outside the classes and don't need it here?\n",
    "\n",
    "from selenium.common.exceptions import (\n",
    "    StaleElementReferenceException, TimeoutException, \n",
    "    ElementClickInterceptedException, ElementNotInteractableException, \n",
    "    NoSuchElementException)\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import getpass\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from geography.classes.UserClass import UserClass\n",
    "from geography.classes.LoginClass import PasswordManager, WebDriverManager, Login\n",
    "from geography.classes.NoLinkClass import NoLinkClass\n",
    "#from geography.classes.DownloadClass import Download\n",
    "from geography.classes.conversions.status_excel_to_pdf import convert_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium.common.exceptions import (\n",
    "    StaleElementReferenceException, TimeoutException, \n",
    "    ElementClickInterceptedException, ElementNotInteractableException, \n",
    "    NoSuchElementException)\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "\n",
    "class ResetRequiredException(Exception):\n",
    "    pass\n",
    "\n",
    "class SkipRowException(Exception):\n",
    "    pass\n",
    "\n",
    "class SingleResultException(Exception):\n",
    "    pass\n",
    "\n",
    "class Download:\n",
    "\n",
    "    def __init__(self, driver, basin_code, user_name, index, login, nlc, download_type, download_folder: str, download_folder_temp, status_file, finished, url = None, timeout = 20):\n",
    "        self.driver = driver\n",
    "        self.basin_code = basin_code\n",
    "        self.user_name = user_name\n",
    "        self.index = index\n",
    "        self.login = login\n",
    "        self.nlc = nlc\n",
    "        self.download_type = download_type\n",
    "        self.status_file = status_file # \n",
    "        self.finished = finished #\n",
    "        self.url = url\n",
    "        self.timeout = timeout\n",
    "        self.download_folder = download_folder #\n",
    "        self.download_folder_temp = download_folder_temp #\n",
    "        \n",
    "        #Set Basin Status CSV File \n",
    "        self.status_data = pd.read_csv(status_file, index_col=0)\n",
    "        #self.result_tally = 0  # initialize it at 0\n",
    "    \n",
    "    def _click_from_xpath(self, xpath):\n",
    "        try:\n",
    "            element = WebDriverWait(self.driver, self.timeout).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, xpath)))\n",
    "            element.click()\n",
    "        except TimeoutException:\n",
    "            raise NoSuchElementException(f\"Element with xpath '{xpath}' not found\")\n",
    "        \n",
    "        #can move if run-through containing xpaths works \n",
    "        #wait = WebDriverWait(driver, 10)\n",
    "        #element = wait.until(EC.element_to_be_clickable((By.XPATH, xpath))) \n",
    "        #self.driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "        #element.click()\n",
    "\n",
    "    def _send_keys_from_xpath(self, xpath, keys):\n",
    "        wait = WebDriverWait(self.driver, self.timeout)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.XPATH, xpath))) \n",
    "        self.driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "        element.send_keys(keys)\n",
    "\n",
    "    def _click_from_css(self, css_selector):\n",
    "        try:\n",
    "            element = WebDriverWait(self.driver, self.timeout).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector))\n",
    "            )\n",
    "            element.click()\n",
    "        except TimeoutException:\n",
    "            raise NoSuchElementException(f\"Element with selector '{css_selector}' not found\")\n",
    "\n",
    "       \n",
    "    def _send_keys_from_css(self, css_selector, keys):\n",
    "        element = WebDriverWait(self.driver, self.timeout).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, css_selector))\n",
    "        )\n",
    "        element.send_keys(keys)\n",
    "\n",
    "    def open_timeline(self):\n",
    "        timeline_button = '#podfiltersbuttondatestr-news' # this is CSS selector\n",
    "        self._click_from_css(timeline_button)\n",
    "        time.sleep(10)\n",
    "        # instead try with XPath\n",
    "        #wait = WebDriverWait(driver, 10)\n",
    "        #timeline_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"/html/body/main/div/main/ln-gns-resultslist/div[2]/div/div[1]/div[1]/div[2]/div/aside/button[2]\")))\n",
    "        #timeline_button.click()\n",
    "        #time.sleep(5)\n",
    "\n",
    "    def parse_date(self, date_string):\n",
    "        date_formats = [\n",
    "            '%m/%d/%y',  # 8/1/08\n",
    "            '%m/%d/%Y',  # 8/1/2008\n",
    "            '%Y-%m-%d',  # 2008-08-01\n",
    "            '%d-%m-%Y',  # 01-08-2008\n",
    "            '%Y/%m/%d',  # 2008/08/01\n",
    "            # Add more formats as needed\n",
    "        ]\n",
    "        \n",
    "        for date_format in date_formats:\n",
    "            try:\n",
    "                return datetime.strptime(date_string, date_format)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        # If no format worked, raise an error\n",
    "        raise ValueError(f\"Unable to parse date string: {date_string}\")\n",
    "        # this would be a good place to add an exception\n",
    "        #and then maybe add in a skip/break of the loop, move to next index #\n",
    "    \n",
    "    def set_date_range(self, index):\n",
    "\n",
    "        #START_DATE AND END_DATE get established here\n",
    "        row = self.status_data.index.get_loc(index)\n",
    "        start_date_column = self.status_data.columns.get_loc('start_date')\n",
    "        end_date_column = self.status_data.columns.get_loc('end_date')\n",
    "\n",
    "        self.start_date_raw = self.status_data.iloc[row, start_date_column]\n",
    "        self.end_date_raw = self.status_data.iloc[row, end_date_column]\n",
    "\n",
    "        try:\n",
    "            start_date_str = self.parse_date(self.start_date_raw)\n",
    "            end_date_str = self.parse_date(self.end_date_raw)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error parsing dates for index {index}: {e}\")\n",
    "            return\n",
    "\n",
    "        self.start_date = start_date_str.strftime('%m/%d/%Y')\n",
    "        self.end_date = end_date_str.strftime('%m/%d/%Y')\n",
    "\n",
    "        print(f\"Setting the date range from {self.start_date} to {self.end_date}\")\n",
    "        time.sleep(1)\n",
    "              \n",
    "        # these are css selectors\n",
    "        #min_date_field = '#refine > div.supplemental.timeline > div.date-form > div.min-picker > input'\n",
    "        #max_date_field = '#refine > div.supplemental.timeline > div.date-form > div.max-picker > input'\n",
    "        \n",
    "        # trying again with xpaths instead of css selector\n",
    "        self.min_date_field = \"//input[@class='min-val' and @aria-label='Input Min Date']\"\n",
    "        self.max_date_field = \"//input[@class='max-val' and @aria-label='Input Max Date']\"\n",
    "\n",
    "        # need to include error handling for when timeline freezes, see what David did\n",
    "        \n",
    "\n",
    "        try:\n",
    "            self._click_from_xpath(self.min_date_field)\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            print('timeline closed or frozen')\n",
    "            self.open_timeline()\n",
    "            time.sleep(5)\n",
    "            #driver.refresh() # does that work? or:\n",
    "            #search_link = driver.current_url\n",
    "            #driver.get(search_link) # ??? or:\n",
    "            #driver.execute_script(\"location.reload()\")\n",
    "            # if after five tries, still no timeline, reset login information\n",
    "\n",
    "        # Clear out the default min date\n",
    "        #self._click_from_css(min_date_field)\n",
    "        time.sleep(5)\n",
    "        self.select_all = Keys.COMMAND, \"a\"\n",
    "        #self._send_keys_from_css(min_date_field, select_all); \n",
    "\n",
    "        # try with xpath\n",
    "        self._send_keys_from_xpath(self.min_date_field, self.select_all); \n",
    "        # Put the new min date in \n",
    "        self._send_keys_from_xpath(self.min_date_field, self.start_date)\n",
    "        print (f\"Min date set to {self.start_date}\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Clear out the default max date \n",
    "        self._send_keys_from_xpath(self.max_date_field, self.select_all); \n",
    "        # Put the new max date in \n",
    "        self._send_keys_from_xpath(self.max_date_field, self.end_date)\n",
    "        print (f\"Max date set to {self.end_date}\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        timeline_ok_button = '#refine > div.supplemental.timeline > div.date-form > button'\n",
    "\n",
    "        try:\n",
    "            self._click_from_css(timeline_ok_button)\n",
    "            time.sleep(10) \n",
    "        except NoSuchElementException:\n",
    "            self.driver.refresh()\n",
    "            print (f\"resetting dates to default\")\n",
    "            raise SingleResultException\n",
    "        \n",
    "    def check_datefilter(self):\n",
    "        self.timeline_reset_button = '#sidebar > div.search-controls > div.filter-container.filterpanel-target > ul > li:nth-child(2) > button > span'\n",
    "        try:\n",
    "            WebDriverWait(self.driver, 20).until(EC.visibility_of_element_located((\n",
    "                By.CSS_SELECTOR, self.timeline_reset_button)))\n",
    "            #print(\"results already have a timeline filter applied\")\n",
    "            return True\n",
    "        except TimeoutException:\n",
    "            #print(\"no timeline filter applied to results\")\n",
    "            return False\n",
    "\n",
    "    def timeline_reset(self): \n",
    "        \n",
    "        if self.check_datefilter():\n",
    "            self._click_from_css(self.timeline_reset_button)\n",
    "            print(\"Cleared previous timeline filter\")\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            #print(\"Default time filter\")\n",
    "            self.open_timeline()\n",
    "\n",
    "    ''' \n",
    "    # commenting out because I think we'll set date range every row \n",
    "\n",
    "    def timeline_by_type(self, index): #change this name eventually\n",
    "\n",
    "        #row = self.status_data.index.get_loc(index)\n",
    "        row = self.status_data.iloc[index] #  this\n",
    "        self.set_date = row['set_date']\n",
    "        \n",
    "        if self.download_type == 'excel':\n",
    "\n",
    "            self.timeline_reset()\n",
    "            print(\"Opening timeline\")\n",
    "            self.set_date_range(index)\n",
    "\n",
    "        else: # don't need to clear timeline filter for pdf unless set_date is 1\n",
    "\n",
    "            #   click clear_timeline # or whatever\n",
    "            if self.set_date == 1:\n",
    "\n",
    "                self.timeline_reset()\n",
    "                self.set_date_range(index)\n",
    "\n",
    "                # and then reset the timeline\n",
    "\n",
    "            else:\n",
    "                # if there is already timelie filter, pass\n",
    "                pass # or continue?\n",
    "    '''\n",
    "\n",
    "    def group_duplicates(self):\n",
    "        actions_dropdown_xpath = \"//button[@id='resultlistactionmenubuttonhc-yk' and text()='Actions']\"\n",
    "        time.sleep(5)\n",
    "        self._click_from_xpath(actions_dropdown_xpath)\n",
    "        time.sleep(5)\n",
    "        moderate_button = \"//button[contains(@class, 'action') and @data-action='changeduplicates' and @data-value='moderate']\"\n",
    "        self._click_from_xpath(moderate_button)\n",
    "        print(\"group duplicate results by moderate similarity\")\n",
    "        time.sleep(10)\n",
    "    \n",
    "    def sort_by_date(self):\n",
    "        sortby_dropdown_css = '#select'\n",
    "        oldestnewest_option_text = 'Date (oldest-newest)'\n",
    "            \n",
    "        def handle_popup():\n",
    "            analytics_popup = \"//button[@class='_pendo-close-guide' and @aria-label='Close' and contains(@id, 'pendo-close-guide')]\"\n",
    "            try:\n",
    "                popup_element = WebDriverWait(self.driver, 5).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, analytics_popup))\n",
    "                )\n",
    "                popup_element.click()\n",
    "                print(\"Popup closed\")\n",
    "                time.sleep(2)\n",
    "            except TimeoutException:\n",
    "                print(\"No popup found\") \n",
    "\n",
    "        for attempt in range(3):  # Try up to 3 times\n",
    "            try:\n",
    "                # Check for and close popup before interacting with dropdown\n",
    "                handle_popup()\n",
    "\n",
    "                # Wait for the dropdown to be clickable\n",
    "                dropdown = WebDriverWait(self.driver, 20).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, sortby_dropdown_css))\n",
    "                )\n",
    "                \n",
    "                # Use Select class to interact with the dropdown\n",
    "                select = Select(dropdown)\n",
    "                select.select_by_visible_text(oldestnewest_option_text)\n",
    "                \n",
    "                print(\"Selected 'Date (oldest-newest)' option\")\n",
    "                time.sleep(5)  # Wait for the page to update\n",
    "                return  # Success, exit the function\n",
    "                \n",
    "            except StaleElementReferenceException:\n",
    "                print(\"Stale element, retrying...\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "                \n",
    "            except (TimeoutException, NoSuchElementException):\n",
    "                print(f\"Attempt {attempt + 1}: Can't find sort-by dropdown, refreshing the page\")\n",
    "                self.driver.refresh()\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "                \n",
    "            except ElementClickInterceptedException:\n",
    "                print(\"Popup is in the way, attempting to close it\")\n",
    "                handle_popup()\n",
    "                continue\n",
    "                \n",
    "            except ElementNotInteractableException:\n",
    "                print(\"Element not interactable, attempting to close popup if present\")\n",
    "                handle_popup()\n",
    "                continue\n",
    "        \n",
    "        print(\"Failed to sort by date after multiple attempts\")\n",
    "\n",
    "    def DownloadSetup(self):\n",
    "        self.group_duplicates()\n",
    "        self.sort_by_date()\n",
    "\n",
    "    def get_result_count(self, index, max_attempts=3):\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                # Wait for the element to be present\n",
    "                count_element = WebDriverWait(self.driver, self.timeout).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"#sidebar > div.search-controls > div.content-type-container.isBisNexisRedesign > ul > li.active\"))\n",
    "                )\n",
    "                \n",
    "                # Wait for the attribute to be non-empty\n",
    "                WebDriverWait(self.driver, self.timeout).until(\n",
    "                    lambda d: count_element.get_attribute(\"data-actualresultscount\") != \"\"\n",
    "                )\n",
    "                \n",
    "                result_count_element = count_element.get_attribute(\"data-actualresultscount\")\n",
    "                self.result_count = int(result_count_element)\n",
    "                return self.result_count\n",
    "\n",
    "            except TypeError:\n",
    "                print(\"Result count type error, waiting 20s for count to appear\")\n",
    "                time.sleep(20)\n",
    "                continue\n",
    "\n",
    "            except (TimeoutException, NoSuchElementException, StaleElementReferenceException) as e:\n",
    "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt < max_attempts - 1:\n",
    "                    print(\"Refreshing page and retrying...\")\n",
    "                    self.driver.refresh()\n",
    "                    time.sleep(5)  # Wait for page to reload\n",
    "                else:\n",
    "                    print(\"Max attempts reached. Could not retrieve result count.\")\n",
    "                    if download_type == 'excel':\n",
    "                        self.status_data.loc[index, 'basin_count'] = None\n",
    "                    else:\n",
    "                        self.status_data.loc[index, 'total_count'] = None\n",
    "                    self.status_data.to_csv(self.status_file)\n",
    "                    return None\n",
    "\n",
    "            except ValueError as e:\n",
    "                print(f\"Error converting result count to integer: {str(e)}\")\n",
    "                if download_type == 'excel':\n",
    "                    self.status_data.loc[index, 'basin_count'] = None\n",
    "                else:\n",
    "                    self.status_data.loc[index, 'total_count'] = None\n",
    "                self.status_data.to_csv(self.status_file)\n",
    "                return None\n",
    "\n",
    "    def add_over_thousand_rows(self, index):\n",
    "\n",
    "        # copy everything from the row where over_thousand is hit\n",
    "        new_row = self.status_data.loc[index, ]\n",
    "\n",
    "        # three columns' values will need to change to these values\n",
    "        new_index = int(len(self.status_data)) # index\n",
    "        new_start_count = new_row.loc[\"stop_count\"] + 1 # start_count\n",
    "        new_stop_count = new_start_count + 499 # stop_count\n",
    "\n",
    "        # and be replaced in the dataframe\n",
    "        new_row.loc['index'] = new_index\n",
    "        new_row.loc['start_count'] = new_start_count\n",
    "        new_row.loc['stop_count'] = new_stop_count\n",
    "\n",
    "        # turn it into a dataframe\n",
    "        add_df = pd.DataFrame(new_row).transpose()\n",
    "\n",
    "        self.status_data = pd.concat([self.status_data, add_df])\n",
    "        self.status_data.to_csv(self.status_file, index=False)\n",
    "        time.sleep(2)\n",
    "\n",
    "                \n",
    "    def result_count_to_df(self, index):\n",
    "               \n",
    "        if self.download_type == 'excel':\n",
    "            # Update status data and return result\n",
    "            self.status_data.loc[index, 'basin_count'] = self.result_count\n",
    "            self.status_data.to_csv(self.status_file)\n",
    "            print(f\"row {index} updated with {self.result_count} results in date range\")\n",
    "            return self.result_count\n",
    "\n",
    "        else: #if self.download_type == 'pdf':\n",
    "            self.start_count = self.status_data.loc[index, 'start_count']\n",
    "            self.stop_count = self.status_data.loc[index, 'stop_count']\n",
    "\n",
    "            # if the range of results exceeds results to be downloaded in this row\n",
    "            if self.result_count > self.stop_count:\n",
    "\n",
    "                # and if there are over 1000 results\n",
    "                if self.stop_count >= 1000:\n",
    "                   print(\"need to add another row\")\n",
    "                   self.add_over_thousand_rows(index)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                self.file_count = int((self.stop_count - self.start_count) + 1)\n",
    "                self.status_data.loc[index, 'total_count'] = self.file_count\n",
    "                print(f\"row {index} updated with {self.file_count} results to be downloaded\")\n",
    "                self.status_data.to_csv(self.status_file)\n",
    "\n",
    "                \n",
    "            else: # if the results end in this row / result_count is lower than stop_count\n",
    "                # update end count\n",
    "                self.file_count = int((self.result_count - self.start_count) + 1)\n",
    "                self.status_data.loc[index, 'total_count'] = self.file_count\n",
    "                #self.status_data.loc[index, 'stop_count'] = self.result_count\n",
    "                print(f\"row {index} updated with {self.file_count} results to be downloaded\")\n",
    "                self.status_data.to_csv(self.status_file)\n",
    "\n",
    "                if self.result_count < 501:\n",
    "                    self.next_row = index + 1\n",
    "                    print(f\"row {index} includes all results in date range\")\n",
    "                    print(f\"updating row {self.next_row} status to automatically skip\")\n",
    "                    self.status_data.loc[self.next_row, 'total_count'] = 0\n",
    "                    self.status_data.loc[self.next_row, 'finished'] = 1\n",
    "                    #self.status_data.loc[next_row, 'start_count'] = 0\n",
    "                    #self.status_data.loc[next_row, 'stop_count'] = 0\n",
    "                    self.status_data.to_csv(self.status_file)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "    def result_count_handling(self, index):\n",
    "\n",
    "        if self.result_count < 1000:\n",
    "            self.result_count_to_df(index)        \n",
    "\n",
    "        else:\n",
    "            # If result count is 1000 or more, check one more time\n",
    "            print(\"Result count is 1000 or more. Checking again...\")\n",
    "            time.sleep(5)  # Wait a bit before checking again\n",
    "\n",
    "            if not self.check_datefilter():\n",
    "                print(\"timeline isn't filtered\")\n",
    "                self.DateFilter(index) # will this cause an infinite loop? \n",
    "\n",
    "            else:\n",
    "                print('result_count is over one thousand')\n",
    "            # Repeat the process to get the count again\n",
    "\n",
    "            count_element = WebDriverWait(self.driver, self.timeout).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"#sidebar > div.search-controls > div.content-type-container.isBisNexisRedesign > ul > li.active\"))\n",
    "            )\n",
    "            result_count_element = count_element.get_attribute(\"data-actualresultscount\")\n",
    "            self.result_count = int(result_count_element)\n",
    "            print(f\"Second check result count for row {index} is {self.result_count}\")\n",
    "\n",
    "            # check here if the timeline is filtered! It might not be!\n",
    "            \n",
    "                #self.DateFilter(index)    \n",
    "                #time.sleep(5)\n",
    "\n",
    "            if self.result_count < 1000:\n",
    "                self.result_count_to_df(index) \n",
    "\n",
    "            else:\n",
    "                #self.DateFilter(index)    \n",
    "                time.sleep(5)\n",
    "                \n",
    "                if self.result_count < 1000:\n",
    "                    self.result_count_to_df(index) \n",
    "                else:\n",
    "                    # If still 1000 or more, update status data and raise SkipRowException\n",
    "                    if download_type == 'excel':\n",
    "                        self.status_data.loc[index, 'basin_count'] = self.result_count\n",
    "                        self.status_data.loc[index, 'over_one_thousand'] = 1\n",
    "                        self.status_data.to_csv(self.status_file)\n",
    "                        raise SkipRowException(f\"Result count is still {self.result_count} after third check.\")\n",
    "                    else:\n",
    "                        #OR raise OverThousandException # tbd on if I want to do this\n",
    "                        self.status_data.loc[index, 'over_one_thousand'] = 1\n",
    "                        self.status_data.to_csv(self.status_file)\n",
    "                        self.result_count_to_df(index)\n",
    "                    \n",
    "\n",
    "    # this portion deals with if the downloads in login session exceed 1000 cumulatively\n",
    "    # but I'm actually going to comment it out because idk it's working fine without tally\n",
    "    '''\n",
    "    def tally_result_count(self, index):\n",
    "        current_count = self.get_result_count(index)\n",
    "        self.result_tally += current_count\n",
    "        time.sleep(3)\n",
    "       \n",
    "        if self.result_tally >= 1000:\n",
    "            print(\"exceeded 1000 results downloaded, need to reset StoredLoginInformation\")\n",
    "            time.sleep(30)\n",
    "            self.reset(index) # maybe??\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "            '''\n",
    "\n",
    "    def DateFilter(self, index):\n",
    "\n",
    "        if self.check_datefilter():\n",
    "            print(\"need to clear date filter\")\n",
    "            self.timeline_reset() \n",
    "\n",
    "        print(\"Setting new date range\")\n",
    "        try:\n",
    "            self.set_date_range(index)\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            self.open_timeline()\n",
    "            self.set_date_range(index)\n",
    "        \n",
    "        '''\n",
    "        if self.download_type == 'excel':\n",
    "\n",
    "            if self.check_datefilter():\n",
    "                print(\"need to clear date filter\")\n",
    "                self.timeline_reset() \n",
    "\n",
    "            print(\"Opening timeline to set new date range\")\n",
    "            self.set_date_range(index)\n",
    "\n",
    "        else: # don't need to clear timeline filter for pdf unless set_date is 1\n",
    "\n",
    "            set_date = self.status_data.loc[index, 'set_date']\n",
    "            if set_date == 1:\n",
    "\n",
    "                self.timeline_reset()\n",
    "                self.set_date_range(index)\n",
    "\n",
    "                # and then reset the timeline\n",
    "\n",
    "            if not self.check_datefilter():\n",
    "                self.set_date_range(index)\n",
    "            \n",
    "            else:\n",
    "                # if there is already timeline filter, pass\n",
    "                pass # or continue?\n",
    "                '''\n",
    "        #moved to try block in line 866        \n",
    "        #try:\n",
    "        #    self.get_result_count(index)\n",
    "        #    self.result_count_handling(index)\n",
    "        #except SkipRowException:\n",
    "        #    raise\n",
    "    \n",
    "    def ExcelSegments(self):\n",
    "        # we just want headline, summary, publication, date\n",
    "        self.checkboxes = self.driver.find_elements(By.CSS_SELECTOR, 'input[type=\"checkbox\"]')\n",
    "        self.keep_checked_ids = ['HEA', 'PUB', 'PDT'] # headline, publication, published date\n",
    "        # Scroll into view and uncheck each checkbox if it is checked\n",
    "        for checkbox in self.checkboxes:\n",
    "            id = checkbox.get_attribute('id')\n",
    "            try:    \n",
    "                if checkbox.is_selected() and id not in self.keep_checked_ids:\n",
    "                    ActionChains(self.driver).move_to_element(checkbox).perform()\n",
    "                    checkbox.click()\n",
    "            except Exception as e:\n",
    "                #print(f\"Error processing checkboxes: {e}\")\n",
    "                #print(f\"Error processing checkboxes\") # terminal looks messy printing the whole error but I can keep this if necessary\n",
    "                pass\n",
    "        print(\"unchecked unnecessary columns\")\n",
    "\n",
    "    def get_filename(self, index):\n",
    "        if self.download_type == 'excel':\n",
    "            self.filename = f'ResultsList_{self.basin_code}_index{index}'\n",
    "            return self.filename\n",
    "        else:\n",
    "            self.filename = f'FullText_{self.basin_code}_index{index}'\n",
    "            return self.filename\n",
    "        \n",
    "    def excelDownloadOptions(self, index):\n",
    "    \n",
    "        #results_list_option = WebDriverWait(self.driver, 10).until(EC.element_to_be_clickable\n",
    "        #                    ((By.XPATH, \"//input[@type='radio' and @id='ResultsListOnly']\")))\n",
    "        #results_list_option.click()\n",
    "        results_list_option = \"//input[@type='radio' and @id='ResultsListOnly']\"\n",
    "        self._click_from_xpath(results_list_option)\n",
    "        print(\"choose resultslist download type\")\n",
    "        time.sleep(2)\n",
    "\n",
    "        self.filetype_excel_option = \"//input[@type='radio' and @id='XLSX']\"\n",
    "        print(\"choose excel option\")\n",
    "        self._click_from_xpath(self.filetype_excel_option)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # un-select unnecessary columns\n",
    "        self.ExcelSegments()\n",
    "        time.sleep(2)\n",
    "        \n",
    "        #self.result_list_field = '#SelectedRange' #css\n",
    "        #self.result_range_field = '//*[@id=\"SelectedRange\"]' #xpath copied\n",
    "        #self.result_range_field = \"//input[@type='text' and @id='SelectedRange']\" #xpath my guess\n",
    "\n",
    "        try:\n",
    "            self.result_range_string = f\"1-{self.result_count}\"\n",
    "            print(f\"Results {self.result_range_string}\")\n",
    "            time.sleep(2)\n",
    "        except SingleResultException:\n",
    "            self.result_range_string = f\"{self.result_count}\"\n",
    "            print(f\"Only one result to download\")\n",
    "            time.sleep(2)\n",
    "\n",
    "        # put in results count to download\n",
    "        self._send_keys_from_xpath(self.result_range_field, self.result_range_string)\n",
    "\n",
    "    def pdfDownloadOptions(self):\n",
    "            #status_data... unless it's defined outside the class??\n",
    "            self.start_count = self.status_data.loc[index, 'start_count'] # I shouldn't need this defined in two places but if result_count_to_df hasn't happened (in this case when I start the script on an over_thousand row)\n",
    "            self.stop_count = self.status_data.loc[index, 'stop_count']\n",
    "            self.file_count = int((self.stop_count - self.start_count) + 1)\n",
    "            #self.status_data.loc[index, 'total_count'] = self.file_count # I don't know if this should be here ???\n",
    "\n",
    "            try:\n",
    "                string_end_count = (self.start_count - 1) + self.file_count\n",
    "                self.result_range_string = f\"{self.start_count}-{string_end_count}\"\n",
    "                print(f\"Results {self.result_range_string}\")\n",
    "                time.sleep(2)\n",
    "\n",
    "            except SingleResultException:\n",
    "                self.result_range_string = f\"{self.result_count}\"\n",
    "                print(f\"Only one result to download\")\n",
    "                time.sleep(2)  \n",
    "\n",
    "            MSWord_option = \"//input[@type= 'radio' and @id= 'Docx']\"\n",
    "            self._click_from_xpath(MSWord_option)\n",
    "\n",
    "            separate_files_option = \"//input[@type= 'radio' and @id= 'SeparateFiles']\"\n",
    "            self._click_from_xpath(separate_files_option)\n",
    "\n",
    "            #zip_option = \"//input[@type= 'checkbox' and @id= 'ZipFile']\"\n",
    "            #self._click_from_xpath(zip_option) # it's selected by default when saving individual files\n",
    "            time.sleep(2)\n",
    "\n",
    "            self._send_keys_from_xpath(self.result_range_field, self.result_range_string)\n",
    "            time.sleep(2)\n",
    "\n",
    "    def DownloadDialog(self, index):\n",
    "        open_download_options = \"//button[@class='has_tooltip' and @data-action='downloadopt']\"\n",
    "        self._click_from_xpath(open_download_options)\n",
    "        time.sleep(5) \n",
    "        self.result_range_field = \"//input[@type='text' and @id='SelectedRange']\"\n",
    "\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "\n",
    "                # check if we're in the dialog box by looking for clickable field button\n",
    "                WebDriverWait(self.driver, 10).until(EC.element_to_be_clickable((By.XPATH, self.result_range_field)))\n",
    "                                                     \n",
    "                break  # Exit the loop if successful\n",
    "\n",
    "                # can i change this to like\n",
    "                #if results_list_option:\n",
    "                #   results_list_option.click()\n",
    "\n",
    "            except (NoSuchElementException, TimeoutException):\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Attempt {attempt + 1} failed to open download window, retrying in 10 seconds\")\n",
    "                    time.sleep(10)\n",
    "                    self._click_from_xpath(open_download_options)  # Try opening the download options again\n",
    "                    time.sleep(5)\n",
    "                else:\n",
    "                    print(\"download limit banner appeared, need to reset login\")\n",
    "                    self.reset_needed = True\n",
    "                    raise ResetRequiredException()\n",
    "\n",
    "        if self.download_type == 'excel':\n",
    "            self.excelDownloadOptions()\n",
    "\n",
    "        else:\n",
    "            self.pdfDownloadOptions()\n",
    "        \n",
    "        # rename file name\n",
    "        self.filename_field = \"//input[@type='text' and @id='FileName']\"\n",
    "        self._send_keys_from_xpath(self.filename_field, (Keys.COMMAND, \"a\"))\n",
    "        self.filename = self.get_filename(index)\n",
    "        print(f'changing filename to {self.filename}')\n",
    "        self._send_keys_from_xpath(self.filename_field, self.filename)\n",
    "        print(f\"{self.download_folder_temp}\")\n",
    "        self.check_clear_downloads(index)\n",
    "        time.sleep(5)\n",
    "        self.click_download(index)\n",
    "\n",
    "        #I actually forget where all of this came from \n",
    "        '''\n",
    "        try:\n",
    "            # Your existing pre-download steps\n",
    "            # (like clicking buttons, setting up the download, etc)\n",
    "            \n",
    "            # Use our new download handler for the actual download\n",
    "            if not self.download_handler.process_download(index):\n",
    "                raise SkipRowException(\"Download failed\")\n",
    "                \n",
    "            # Update status if successful\n",
    "            self.status_data.at[index, 'finished'] = 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in download process: {str(e)}\")\n",
    "            #self.reset_needed = True\n",
    "            raise SkipRowException(\"Error during download\")\n",
    "        '''\n",
    "    def check_clear_downloads(self, index): # for a manual check\n",
    "        #if file in default_download contains the name \"Files (\" move it to a folder\n",
    "        self.default_download_name = f\"Files ({self.file_count}).ZIP\"\n",
    "        self.unsorted_past_download = f\"{self.download_folder_temp}/{self.default_download_name}\"\n",
    "        if os.path.exists(os.path.join(self.download_folder_temp, self.default_download_name)):\n",
    "            print(f\"there's an unsorted file matching {self.default_download_name} name in downloads\")\n",
    "            self.create_unsorted_folder(index)\n",
    "            self.move_unsorted()\n",
    "        # or can do regular expression with just \"Files (\"\n",
    "        #\n",
    "        #self.create_unsorted_folder(index)\n",
    "        # if self.unsorted_past_download.is_dir():\n",
    "        #     print(f\"there's an unsorted file matching {self.default_download_name} name in downloads\")\n",
    "\n",
    "        #     self.move_unsorted()\n",
    "        # else:\n",
    "        #     print(\"didn't find a matching file\")\n",
    "        #     pass\n",
    "\n",
    "\n",
    "    def create_unsorted_folder(self, index):\n",
    "        self.unsorted_folder = Path(f\"{self.download_folder}/{self.basin_code}_unsorted_foundindex{index}\") # in default download\n",
    "        if self.unsorted_folder.is_dir():\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            print(f\"creating unsorted folder {self.unsorted_folder}\")\n",
    "            os.makedirs(self.unsorted_folder)\n",
    "\n",
    "        print(f\"to move missing download {self.unsorted_past_download}: check status sheet before index {self.index} for matching file count and check file header for date range to confirm\")\n",
    "\n",
    "    def move_unsorted(self):\n",
    "        unsorted_moved_path = f\"{self.unsorted_folder}/{self.default_download_name}\"\n",
    "        os.rename(self.unsorted_past_download, unsorted_moved_path)\n",
    "        print(f\"file {self.filename} in {self.basin_code} download folder\")\n",
    "\n",
    "    def click_download(self, index): \n",
    "\n",
    "        # check for a file in downloads with the naming convention and handle it!!\n",
    "        # maybe move it to a folder called \"incomplete_discovered_index12\"\n",
    "\n",
    "        try:\n",
    "            self.download_button = \"//button[@type='submit' and @class='button primary' and @data-action='download']\"\n",
    "            self._click_from_xpath(self.download_button)\n",
    "            print(f\"downloading {self.filename}\")\n",
    "            time.sleep(10)\n",
    "            \n",
    "            # Wait for and confirm download\n",
    "            if not self.wait_for_download():\n",
    "                print(f\"Download failed for index {index}\")\n",
    "                return False\n",
    "\n",
    "            time.sleep(5)\n",
    "            # Move file to correct location\n",
    "            #if not self.move_file(index):\n",
    "            #    print(f\"Failed to move file for index {index}\")\n",
    "            #    return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing download for index {index}: {str(e)}\")\n",
    "            return False\n",
    "        \n",
    "\n",
    "        #self.result_count = self.get_result_count(index)       \n",
    "\n",
    "    def wait_for_download(self):\n",
    "\n",
    "        try:\n",
    "            # First, wait for UI indication that download started\n",
    "            print(\"Waiting for download to start...\")\n",
    "            WebDriverWait(self.driver, 120).until(\n",
    "                EC.presence_of_element_located((By.ID, \"delivery-popin\"))\n",
    "            )\n",
    "            print(\"Download started, processing...\")\n",
    "            \n",
    "            # Wait for UI indication that browser finished\n",
    "            WebDriverWait(self.driver, 1000).until_not(\n",
    "                EC.presence_of_element_located((By.ID, \"delivery-popin\"))\n",
    "            )\n",
    "            print(\"Browser reports download complete!\")\n",
    "            return True\n",
    "            # Check Downloads for file default\n",
    "            #actually maybe I want another method\n",
    "    \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            if \"presence_of_element_located\" in str(e):\n",
    "                print(\"Download popup never appeared\")\n",
    "            else:\n",
    "                print(\"Download didn't complete within the timeout period\")\n",
    "\n",
    "\n",
    "    def move_file(self, index):\n",
    "        self.filename = self.get_filename(index)\n",
    "        #self.file_count = int(self.status_data.loc[index, 'total_count'])\n",
    "\n",
    "        if self.download_type == 'excel':\n",
    "\n",
    "            self.default_download_path = f\"{self.download_folder_temp}/{self.filename}.ZIP\"\n",
    "\n",
    "        else:\n",
    "            # for some reason the PDF download filename defaults to \n",
    "            #self.default_download_name = f\"Files ({self.file_count}).ZIP\"\n",
    "            self.default_download_path = f\"{self.download_folder_temp}/{self.default_download_name}\"\n",
    "            print(f\"looking for {self.default_download_name} in default downloads folder\")\n",
    "\n",
    "        self.geography_download_path = f\"{self.download_folder}/{self.filename}.ZIP\"\n",
    "\n",
    " \n",
    "        max_attempts = 3 \n",
    "        attempts = 0\n",
    "\n",
    "        while attempts < max_attempts: \n",
    "                # this attempt stuff could be bypassed if we fix the download wait\n",
    "            try:\n",
    "                os.rename(self.default_download_path, self.geography_download_path)\n",
    "                print(f\"file {self.filename} in {self.basin_code} download folder\")\n",
    "                time.sleep(2)\n",
    "                return True\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"file not found\")\n",
    "                time.sleep(10)\n",
    "                attempts += 1\n",
    "\n",
    "                try:\n",
    "                    self.driver.refresh() # maybe a coincidence but this did the trick last time?\n",
    "                    time.sleep(5)\n",
    "                    os.rename(self.default_download_path, self.geography_download_path)\n",
    "                    print(f\"file successfully moved to {self.basin_code} download folder\")\n",
    "                    time.sleep(2)\n",
    "\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"file missing or not moved, check default download folder\")\n",
    "                    time.sleep(2)\n",
    "\n",
    "\n",
    "    def update_status(self, index):\n",
    "        self.filename = self.get_filename(index)\n",
    "        self.downloaded_file = self.filename + \".ZIP\"\n",
    "        #self.result_count = self.get_result_count(index)\n",
    "        #filename_column\n",
    "        #finished_column\n",
    "        \n",
    "        downloaded_file_path = os.path.join(self.download_folder, self.downloaded_file)\n",
    "        file_exists = os.path.isfile(downloaded_file_path)\n",
    "\n",
    "        if file_exists:\n",
    "            self.status_data.loc[index, 'file_name'] = str(self.filename)\n",
    "            self.status_data.loc[index, 'finished'] = 1\n",
    "            self.status_data.to_csv(self.status_file)\n",
    "            print(f\"status sheet row {index} updated\")\n",
    "        else:\n",
    "            self.status_data.loc[index, 'finished'] = 0\n",
    "            print(f\"row {index} not marked as finished\")\n",
    "\n",
    "    def file_handling(self, index):\n",
    "        self.move_file(index)\n",
    "        self.update_status(index)\n",
    "\n",
    "    def DownloadProcess(self, index):\n",
    "        self.DateFilter(index)\n",
    "        try:\n",
    "            self.get_result_count(index)\n",
    "            self.result_count_handling(index)\n",
    "            self.DownloadDialog(index)  \n",
    "            #download_success = self.wait_for_download() \n",
    "            #if download_success: # this was making something funny happen\n",
    "            #    self.file_handling(index) \n",
    "            self.file_handling(index)\n",
    "        except SkipRowException:\n",
    "            raise\n",
    "        except ResetRequiredException:\n",
    "            raise\n",
    "        # there might be another exception to add here...\n",
    "\n",
    "    # now this part\n",
    "\n",
    "    def main(self, index, basin_code): # why am I not calling index?\n",
    "        print(f\"Download for {basin_code}\")\n",
    "        self.DownloadSetup() \n",
    "        row_index = 0\n",
    "\n",
    "        while row_index < len(self.status_data):\n",
    "\n",
    "            # Check if all rows are finished\n",
    "            if (self.status_data['finished'] == 1).all():\n",
    "                print(f\"All rows for {basin_code} are downloaded!\")\n",
    "                #if self.download_type == \"excel\": # oh is download type not here yet?\n",
    "                    #combine_excel = CombineResults(basin_code)\n",
    "                    #combine_excel.combine()\n",
    "                #else:\n",
    "                #pass\n",
    "                break\n",
    "\n",
    "            row = self.status_data.iloc[row_index] #why is this diff than index?\n",
    "            self.finished = row['finished']\n",
    "            self.over_thousand = row['over_one_thousand']\n",
    "\n",
    "            if self.finished != 1 and self.over_thousand != 1:\n",
    "                try:\n",
    "                    print(f\"Proceeding to download basin {basin_code} row {row_index}\")\n",
    "                    time.sleep(1)\n",
    "                    self.current_row = row\n",
    "                    self.DownloadProcess(row_index)\n",
    "                    row_index += 1  # Move to next row only if successful\n",
    "                except SkipRowException:    \n",
    "                    print(f\"row {row_index} result count exceeds 1000, skipping to next row\")\n",
    "                    self.status_data.at[row_index, 'over_one_thousand'] = 1  # Update status\n",
    "                    row_index += 1  # Move to next row\n",
    "                except ResetRequiredException:\n",
    "                    if self.reset_needed:\n",
    "                        self.reset()\n",
    "                        self.reset_needed = False\n",
    "                        time.sleep(1)\n",
    "                        print(f\"Restarting download process at row {row_index}\")\n",
    "                        # Don't increment row_index, will retry the same row\n",
    "            else:\n",
    "                row_index += 1  # Move to next row if finished or over thousand\n",
    "\n",
    "    def reset(self):\n",
    "        sign_in_button = \"//button[@id='SignInRegisterBisNexis']\"\n",
    "        try:\n",
    "            self._click_from_xpath(sign_in_button)\n",
    "            print(\"logging out\")\n",
    "        except ElementClickInterceptedException:\n",
    "            find_sign_in = driver.find_element(By.XPATH, sign_in_button) # the last error was here\n",
    "            self.driver.execute_script(\"return arguments[0].scrollIntoView(true);\", find_sign_in)\n",
    "        \n",
    "        self.driver.delete_all_cookies()\n",
    "        print(\"deleting cookies before logging in again\")\n",
    "        time.sleep(3)\n",
    "        self.login._init_login()\n",
    "        self.nlc._search_process()\n",
    "        time.sleep(5)\n",
    "        self.DownloadSetup()\n",
    "    \n",
    "\n",
    "download = Download(\n",
    "        driver=driver,\n",
    "        basin_code=basin_code,\n",
    "        user_name=user_name,\n",
    "        index=0,  \n",
    "        login = login,\n",
    "        nlc = nlc,\n",
    "        download_type = download_type,\n",
    "        download_folder = download_folder,\n",
    "        download_folder_temp = download_folder_temp,\n",
    "        status_file=status_file,\n",
    "        finished=False,  \n",
    "        url=None,  \n",
    "        timeout=20 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- interrupted script after row 162\n",
    "- to test break on row 310\n",
    "- so I'm going to force this break by marking all rows from 182-309 as \"finished\"\n",
    "- BUT THEY ARE NOT!! so when I'm done testing\n",
    "- remove the \"1\" from \"finished\" in rows 182-309 in gron pdf status sheet\n",
    "\n",
    "- also shouldn't it only trigger the add row on the second (501-1000) row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download for gron\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Proceeding to download basin gron row 310\n",
      "need to clear date filter\n",
      "Cleared previous timeline filter\n",
      "Setting new date range\n",
      "Setting the date range from 09/02/2012 to 09/08/2012\n",
      "Min date set to 09/02/2012\n",
      "Max date set to 09/08/2012\n",
      "Result count is 1000 or more. Checking again...\n",
      "result_count is over one thousand\n",
      "Second check result count for row 310 is 1094\n",
      "result_count is over 1000, will add rows\n",
      "Results 1-500\n",
      "changing filename to FullText_gron_index310\n",
      "/Users/selenawallace/Downloads/\n",
      "downloading FullText_gron_index310\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Browser reports download complete!\n",
      "looking for Files (500).ZIP in default downloads folder\n",
      "file FullText_gron_index310 in gron download folder\n",
      "status sheet row 310 updated\n",
      "Proceeding to download basin gron row 311\n",
      "need to clear date filter\n",
      "Cleared previous timeline filter\n",
      "Setting new date range\n",
      "Setting the date range from 09/02/2012 to 09/08/2012\n",
      "Min date set to 09/02/2012\n",
      "Max date set to 09/08/2012\n",
      "Result count is 1000 or more. Checking again...\n",
      "result_count is over one thousand\n",
      "Second check result count for row 311 is 1094\n",
      "result_count is over 1000, will add rows\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for gron\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 311\n",
      "Proceeding to download basin gron row 311\n",
      "Setting new date range\n",
      "Setting the date range from 09/02/2012 to 09/08/2012\n",
      "timeline closed or frozen\n",
      "Min date set to 09/02/2012\n",
      "Max date set to 09/08/2012\n",
      "Result count is 1000 or more. Checking again...\n",
      "result_count is over one thousand\n",
      "Second check result count for row 311 is 1094\n",
      "result_count is over 1000, will add rows\n",
      "Results 501-1000\n",
      "changing filename to FullText_gron_index311\n",
      "/Users/selenawallace/Downloads/\n",
      "downloading FullText_gron_index311\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Browser reports download complete!\n",
      "looking for Files (500).ZIP in default downloads folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "row 311 not marked as finished\n",
      "Proceeding to download basin gron row 312\n",
      "need to clear date filter\n",
      "Cleared previous timeline filter\n",
      "Setting new date range\n",
      "Setting the date range from 09/09/2012 to 09/15/2012\n",
      "Min date set to 09/09/2012\n",
      "Max date set to 09/15/2012\n",
      "row 312 updated with 500 results to be downloaded\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for gron\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 312\n",
      "Proceeding to download basin gron row 312\n",
      "Setting new date range\n",
      "Setting the date range from 09/09/2012 to 09/15/2012\n",
      "timeline closed or frozen\n",
      "Min date set to 09/09/2012\n",
      "Max date set to 09/15/2012\n",
      "row 312 updated with 500 results to be downloaded\n",
      "Results 1-500\n",
      "changing filename to FullText_gron_index312\n",
      "/Users/selenawallace/Downloads/\n",
      "downloading FullText_gron_index312\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Browser reports download complete!\n",
      "looking for Files (500).ZIP in default downloads folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "row 312 not marked as finished\n",
      "Proceeding to download basin gron row 313\n",
      "need to clear date filter\n",
      "Cleared previous timeline filter\n",
      "Setting new date range\n",
      "Setting the date range from 09/09/2012 to 09/15/2012\n",
      "Min date set to 09/09/2012\n",
      "Max date set to 09/15/2012\n",
      "row 313 updated with 465 results to be downloaded\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for gron\n",
      "had to click search button again for some reason\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 313\n",
      "Proceeding to download basin gron row 313\n",
      "Setting new date range\n",
      "Setting the date range from 09/09/2012 to 09/15/2012\n",
      "timeline closed or frozen\n",
      "Min date set to 09/09/2012\n",
      "Max date set to 09/15/2012\n",
      "row 313 updated with 465 results to be downloaded\n",
      "Results 501-1000\n",
      "changing filename to FullText_gron_index313\n",
      "/Users/selenawallace/Downloads/\n",
      "downloading FullText_gron_index313\n",
      "Waiting for download to start...\n",
      "Error: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x000000010a6f0d08 chromedriver + 4996360\n",
      "1   chromedriver                        0x000000010a6e85ca chromedriver + 4961738\n",
      "2   chromedriver                        0x000000010a28bd10 chromedriver + 388368\n",
      "3   chromedriver                        0x000000010a2d830f chromedriver + 701199\n",
      "4   chromedriver                        0x000000010a2d83f1 chromedriver + 701425\n",
      "5   chromedriver                        0x000000010a31d464 chromedriver + 984164\n",
      "6   chromedriver                        0x000000010a2fc9dd chromedriver + 850397\n",
      "7   chromedriver                        0x000000010a31aa00 chromedriver + 973312\n",
      "8   chromedriver                        0x000000010a2fc753 chromedriver + 849747\n",
      "9   chromedriver                        0x000000010a2cb635 chromedriver + 648757\n",
      "10  chromedriver                        0x000000010a2cbe5e chromedriver + 650846\n",
      "11  chromedriver                        0x000000010a6b6ff0 chromedriver + 4759536\n",
      "12  chromedriver                        0x000000010a6bbf08 chromedriver + 4779784\n",
      "13  chromedriver                        0x000000010a6bc5d5 chromedriver + 4781525\n",
      "14  chromedriver                        0x000000010a699a99 chromedriver + 4639385\n",
      "15  chromedriver                        0x000000010a6bc8c9 chromedriver + 4782281\n",
      "16  chromedriver                        0x000000010a68b034 chromedriver + 4579380\n",
      "17  chromedriver                        0x000000010a6d89f8 chromedriver + 4897272\n",
      "18  chromedriver                        0x000000010a6d8bf3 chromedriver + 4897779\n",
      "19  chromedriver                        0x000000010a6e81ce chromedriver + 4960718\n",
      "20  libsystem_pthread.dylib             0x00007ff8011dd4e1 _pthread_start + 125\n",
      "21  libsystem_pthread.dylib             0x00007ff8011d8f6b thread_start + 15\n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Download failed for index 313\n",
      "looking for Files (500).ZIP in default downloads folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "row 313 not marked as finished\n",
      "Proceeding to download basin gron row 314\n",
      "need to clear date filter\n",
      "Cleared previous timeline filter\n",
      "Setting new date range\n",
      "Setting the date range from 09/16/2012 to 09/22/2012\n",
      "Min date set to 09/16/2012\n",
      "Max date set to 09/22/2012\n",
      "row 314 updated with 500 results to be downloaded\n",
      "Results 1-500\n",
      "changing filename to FullText_gron_index314\n",
      "/Users/selenawallace/Downloads/\n",
      "downloading FullText_gron_index314\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Browser reports download complete!\n",
      "looking for Files (500).ZIP in default downloads folder\n",
      "file FullText_gron_index314 in gron download folder\n",
      "status sheet row 314 updated\n",
      "Proceeding to download basin gron row 315\n",
      "need to clear date filter\n",
      "Cleared previous timeline filter\n",
      "Setting new date range\n",
      "Setting the date range from 09/16/2012 to 09/22/2012\n",
      "Min date set to 09/16/2012\n",
      "Max date set to 09/22/2012\n",
      "row 315 updated with 319 results to be downloaded\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for gron\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 315\n",
      "Proceeding to download basin gron row 315\n",
      "Setting new date range\n",
      "Setting the date range from 09/16/2012 to 09/22/2012\n",
      "timeline closed or frozen\n",
      "Min date set to 09/16/2012\n",
      "Max date set to 09/22/2012\n",
      "row 315 updated with 319 results to be downloaded\n",
      "Results 501-1000\n",
      "changing filename to FullText_gron_index315\n",
      "/Users/selenawallace/Downloads/\n",
      "downloading FullText_gron_index315\n",
      "Waiting for download to start...\n",
      "Error: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x000000010a6f0d08 chromedriver + 4996360\n",
      "1   chromedriver                        0x000000010a6e85ca chromedriver + 4961738\n",
      "2   chromedriver                        0x000000010a28bd10 chromedriver + 388368\n",
      "3   chromedriver                        0x000000010a2d830f chromedriver + 701199\n",
      "4   chromedriver                        0x000000010a2d83f1 chromedriver + 701425\n",
      "5   chromedriver                        0x000000010a31d464 chromedriver + 984164\n",
      "6   chromedriver                        0x000000010a2fc9dd chromedriver + 850397\n",
      "7   chromedriver                        0x000000010a31aa00 chromedriver + 973312\n",
      "8   chromedriver                        0x000000010a2fc753 chromedriver + 849747\n",
      "9   chromedriver                        0x000000010a2cb635 chromedriver + 648757\n",
      "10  chromedriver                        0x000000010a2cbe5e chromedriver + 650846\n",
      "11  chromedriver                        0x000000010a6b6ff0 chromedriver + 4759536\n",
      "12  chromedriver                        0x000000010a6bbf08 chromedriver + 4779784\n",
      "13  chromedriver                        0x000000010a6bc5d5 chromedriver + 4781525\n",
      "14  chromedriver                        0x000000010a699a99 chromedriver + 4639385\n",
      "15  chromedriver                        0x000000010a6bc8c9 chromedriver + 4782281\n",
      "16  chromedriver                        0x000000010a68b034 chromedriver + 4579380\n",
      "17  chromedriver                        0x000000010a6d89f8 chromedriver + 4897272\n",
      "18  chromedriver                        0x000000010a6d8bf3 chromedriver + 4897779\n",
      "19  chromedriver                        0x000000010a6e81ce chromedriver + 4960718\n",
      "20  libsystem_pthread.dylib             0x00007ff8011dd4e1 _pthread_start + 125\n",
      "21  libsystem_pthread.dylib             0x00007ff8011d8f6b thread_start + 15\n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Download failed for index 315\n",
      "looking for Files (500).ZIP in default downloads folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "row 315 not marked as finished\n",
      "Proceeding to download basin gron row 316\n",
      "need to clear date filter\n",
      "Cleared previous timeline filter\n",
      "Setting new date range\n",
      "Setting the date range from 09/23/2012 to 09/29/2012\n",
      "Min date set to 09/23/2012\n",
      "Max date set to 09/29/2012\n",
      "Result count is 1000 or more. Checking again...\n",
      "result_count is over one thousand\n",
      "Second check result count for row 316 is 1267\n",
      "result_count is over 1000, will add rows\n",
      "Results 1-500\n",
      "changing filename to FullText_gron_index316\n",
      "/Users/selenawallace/Downloads/\n",
      "downloading FullText_gron_index316\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Error: Message: \n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Download failed for index 316\n",
      "looking for Files (500).ZIP in default downloads folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "file not found\n",
      "file missing or not moved, check default download folder\n",
      "row 316 not marked as finished\n",
      "Proceeding to download basin gron row 317\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdownload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasin_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasin_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mDownload.main\u001b[0;34m(self, index, basin_code)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProceeding to download basin \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbasin_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 908\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_row \u001b[38;5;241m=\u001b[39m row\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDownloadProcess(row_index)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "download.main(index=0, basin_code=basin_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing new row for over thousand\n",
    "- note that there may need to be a similar update for download_type == 'excel'\n",
    "\n",
    "- * when over_thousand is triggered, it skips the row. \n",
    "- - we want it to add rows but not skip download row\n",
    "- - so the way it's programmed now, only raise skiprowexception if excel\n",
    "- - and the row is added in the handling phase, has nothing to do with remainder of process\n",
    "\n",
    "- * can it add an additional row (in other words, \"over 1500 handling\")\n",
    "- - did \" if self.stop_count >= 1000 \" work?\n",
    "- - might I try some kinda while loop?\n",
    "\n",
    "overthousand_count = result_count - 1000\n",
    "#   if overthousand_count < 501:\n",
    "#       add a row\n",
    "#   else:\n",
    "#       add two rows\n",
    "# this will have to be a loop      \n",
    "#       if overthousand_count > 1000\n",
    "#           add a row\n",
    "\n",
    "#while overthousand_count > 1000:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another possible problem,\n",
    "# in adition to the filename defaulting to like whatever\n",
    "# it also takes a bit longer for pdf to download"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
