{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "import pwd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting pdf process for selena\n"
     ]
    }
   ],
   "source": [
    "from geography.classes.UserClass import UserClass\n",
    "from geography.classes.LoginClass import PasswordManager, WebDriverManager, Login\n",
    "from geography.classes.NoLinkClass import NoLinkClass\n",
    "from geography.classes.DownloadClass import Download\n",
    "\n",
    "basin_code = \"tigr\"\n",
    "master_user = \"selena\"\n",
    "download_type = \"pdf\"\n",
    "\n",
    "currentUser = UserClass(basin_code, master_user, download_type)\n",
    "currentUser.getName()\n",
    "paths = currentUser.getPath(download_type)\n",
    "user_name = paths[\"user_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncomputer_name = pwd.getpwuid(os.getuid()).pw_name\\nbase_path = f\\'/Users/{computer_name}\\'\\ntemp_download_folder = f\\'{base_path}/Downloads/\\'\\ngeography_folder = f\\'{base_path}/Documents/geography\\'\\ngeo_download_folder = f\\'{geography_folder}/data/downloads/{basin_code}/{download_type}\\'\\n\\n\\nstatus_file = f\"{geography_folder}/data/status/{download_type}/{basin_code}.csv\"\\nstatus_data = pd.read_csv(status_file)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UPDATE USER CLASS WITH THESE\n",
    "\n",
    "user_name = paths[\"user_name\"]\n",
    "geography_folder = paths[\"geography_folder\"]\n",
    "download_folder_temp = paths[\"download_folder_temp\"]\n",
    "download_folder = paths[\"download_folder\"]\n",
    "status_file = paths[\"status_file\"]\n",
    "\n",
    "\n",
    "\n",
    "# maybe in the paths section, then maybe \"user_name\" runs get_user\n",
    "#if os = mac\n",
    "'''\n",
    "computer_name = pwd.getpwuid(os.getuid()).pw_name\n",
    "base_path = f'/Users/{computer_name}'\n",
    "temp_download_folder = f'{base_path}/Downloads/'\n",
    "geography_folder = f'{base_path}/Documents/geography'\n",
    "geo_download_folder = f'{geography_folder}/data/downloads/{basin_code}/{download_type}'\n",
    "\n",
    "\n",
    "status_file = f\"{geography_folder}/data/status/{download_type}/{basin_code}.csv\"\n",
    "status_data = pd.read_csv(status_file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password set!\n",
      "User is not logged in. Proceeding with login...\n",
      "Logging in user with userName swalla05\n",
      "Entered Tufts username and password\n",
      "skipped update chrome page\n",
      "DUO authentication prompted\n",
      "DUO push code on screen OR wait for call\n",
      "DUO push entered, skipping trust browser page\n",
      "DUO authentication completed\n",
      "DUO authentication successful\n",
      "DUO authentication successful\n",
      "login successful\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "\n",
    "    pm = PasswordManager()\n",
    "    if pm.password is None:\n",
    "        password = pm.get_password()\n",
    "        print(\"Password set!\")\n",
    "    else: pass\n",
    "        \n",
    "    manager = WebDriverManager()\n",
    "    #options = manager.setup_options()\n",
    "    driver = manager.start_driver()\n",
    "\n",
    "    time.sleep(5)\n",
    "    login = Login(user_name=user_name, password=password, driver_manager=manager, url=None)\n",
    "        \n",
    "    login._init_login()\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n"
     ]
    }
   ],
   "source": [
    "computer_name = pwd.getpwuid(os.getuid()).pw_name\n",
    "base_path = f'/Users/{computer_name}'\n",
    "# this part here ^ doesn't exist in userclass but I'd like to add it\n",
    "\n",
    "nlc = NoLinkClass(driver, basin_code, download_type, base_path)\n",
    "nlc._search_process()\n",
    "time.sleep(10)\n",
    "\n",
    "# sometimes there's an error on clicking the search_button in complete_search method\n",
    "# I changed it to an xpath from css... the next thing to try if the issue recurs is a check and click again\n",
    "# it could also be an issue of not sleeping enough time after sending search terms\n",
    "\n",
    "#nlc.complete_search() # because if I run this separately it clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "class DownloadManager:\n",
    "    def __init__(self, chrome_options):\n",
    "        \"\"\"Initialize the download manager with existing chrome options.\"\"\"\n",
    "        # Create a temporary directory that will be automatically cleaned up\n",
    "        self.temp_dir = tempfile.mkdtemp(prefix=\"safe_downloads_\")\n",
    "        \n",
    "        # Add download directory preference to existing chrome options\n",
    "        prefs = {\n",
    "            \"download.default_directory\": self.temp_dir,\n",
    "            \"download.prompt_for_download\": False,  # Disable download prompt\n",
    "            \"download.directory_upgrade\": True\n",
    "        }\n",
    "        chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "        \n",
    "        self.downloaded_files = []\n",
    "\n",
    "    def wait_for_download(self, timeout=60):\n",
    "        \"\"\"Wait for a file to appear in the temp directory.\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while time.time() - start_time < timeout:\n",
    "            files = os.listdir(self.temp_dir)\n",
    "            # Filter out partial downloads (ending in .crdownload)\n",
    "            complete_files = [f for f in files if not f.endswith('.crdownload')]\n",
    "            \n",
    "            if complete_files:\n",
    "                file_path = os.path.join(self.temp_dir, complete_files[0])\n",
    "                self.downloaded_files.append(file_path)\n",
    "                return file_path\n",
    "                \n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        raise TimeoutError(f\"No download completed within {timeout} seconds\")\n",
    "\n",
    "    def move_latest_download(self, destination_path):\n",
    "        \"\"\"Move the most recently downloaded file to a new location.\"\"\"\n",
    "        if not self.downloaded_files:\n",
    "            raise FileNotFoundError(\"No downloads have been recorded\")\n",
    "            \n",
    "        latest_file = self.downloaded_files[-1]\n",
    "        if not os.path.exists(latest_file):\n",
    "            raise FileNotFoundError(f\"Downloaded file no longer exists: {latest_file}\")\n",
    "            \n",
    "        # Create the destination directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
    "        \n",
    "        # Move the file to its new location\n",
    "        shutil.move(latest_file, destination_path)\n",
    "        return destination_path\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up the temporary directory.\"\"\"\n",
    "        try:\n",
    "            shutil.rmtree(self.temp_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to clean up temporary directory: {e}\")\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Allow usage with 'with' statement.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Ensure cleanup happens even if an error occurs.\"\"\"\n",
    "        self.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadHandler:\n",
    "    def __init__(self, driver, download_folder, basin_code):\n",
    "        self.driver = driver\n",
    "        self.download_folder = download_folder\n",
    "        self.basin_code = basin_code\n",
    "        \n",
    "        # Initialize download manager with existing driver options\n",
    "        self.download_manager = DownloadManager(self.driver.options)\n",
    "        \n",
    "        # Ensure download folder exists\n",
    "        os.makedirs(self.download_folder, exist_ok=True)\n",
    "\n",
    "    def process_download(self, index):\n",
    "        \"\"\"Main method that would be called from your larger process\"\"\"\n",
    "        try:\n",
    "            # Your existing download triggering code would go here\n",
    "            # (clicking buttons, etc)\n",
    "            \n",
    "            # Wait for and confirm download\n",
    "            if not self.wait_for_download():\n",
    "                print(f\"Download failed for index {index}\")\n",
    "                return False\n",
    "\n",
    "            # Move file to correct location\n",
    "            if not self.move_file(index):\n",
    "                print(f\"Failed to move file for index {index}\")\n",
    "                return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing download for index {index}: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    # Your existing methods, modified to work with DownloadManager\n",
    "    def wait_for_download(self):\n",
    "        try:\n",
    "            print(\"Waiting for download to start...\")\n",
    "            WebDriverWait(self.driver, 60).until(\n",
    "                EC.presence_of_element_located((By.ID, \"delivery-popin\"))\n",
    "            )\n",
    "            print(\"Download started, processing...\")\n",
    "            \n",
    "            WebDriverWait(self.driver, 120).until_not(\n",
    "                EC.presence_of_element_located((By.ID, \"delivery-popin\"))\n",
    "            )\n",
    "            print(\"Browser reports download complete!\")\n",
    "            \n",
    "            # Confirm file exists\n",
    "            self.download_manager.wait_for_download(timeout=30)\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error waiting for download: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def move_file(self, index):\n",
    "        filename = self.get_filename(index)  # Your existing filename generation\n",
    "        destination_path = f\"{self.download_folder}/{filename}.ZIP\"\n",
    "        \n",
    "        max_attempts = 3\n",
    "        attempts = 0\n",
    "        \n",
    "        while attempts < max_attempts:\n",
    "            try:\n",
    "                self.download_manager.move_latest_download(destination_path)\n",
    "                print(f\"File moved to {self.basin_code} folder\")\n",
    "                time.sleep(2)\n",
    "                return True\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found on attempt {attempts + 1}\")\n",
    "                time.sleep(10)\n",
    "                attempts += 1\n",
    "        \n",
    "        try:\n",
    "            self.driver.refresh()\n",
    "            time.sleep(5)\n",
    "            self.download_manager.move_latest_download(destination_path)\n",
    "            print(f\"File moved to {self.basin_code} folder after refresh\")\n",
    "            return True\n",
    "        except FileNotFoundError:\n",
    "            print(\"File missing or not moved\")\n",
    "            return False\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Call this when done with all downloads\"\"\"\n",
    "        if hasattr(self, 'download_manager'):\n",
    "            self.download_manager.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import (\n",
    "    StaleElementReferenceException, TimeoutException, \n",
    "    ElementClickInterceptedException, ElementNotInteractableException, \n",
    "    NoSuchElementException)\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "class ResetRequiredException(Exception):\n",
    "    pass\n",
    "\n",
    "class SkipRowException(Exception):\n",
    "    pass\n",
    "\n",
    "class SingleResultException(Exception):\n",
    "    pass\n",
    "\n",
    "class Download:\n",
    "\n",
    "    def __init__(self, driver, basin_code, user_name, index, login, nlc, download_type, download_folder: str, download_folder_temp, status_file, finished, url = None, timeout = 20):\n",
    "        self.driver = driver\n",
    "        self.basin_code = basin_code\n",
    "        self.user_name = user_name\n",
    "        self.index = index\n",
    "        self.login = login\n",
    "        self.nlc = nlc\n",
    "        self.download_type = download_type\n",
    "        self.status_file = status_file # \n",
    "        self.finished = finished #\n",
    "        self.url = url\n",
    "        self.timeout = timeout\n",
    "        self.download_folder = download_folder #\n",
    "        self.download_folder_temp = download_folder_temp #\n",
    "\n",
    "        self.download_manager = DownloadManager(self.driver.options)\n",
    "        \n",
    "        #Set Basin Status CSV File \n",
    "        self.status_data = pd.read_csv(status_file, index_col=0)\n",
    "        #self.result_tally = 0  # initialize it at 0\n",
    "    \n",
    "    def _click_from_xpath(self, xpath):\n",
    "        try:\n",
    "            element = WebDriverWait(self.driver, self.timeout).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, xpath)))\n",
    "            element.click()\n",
    "        except TimeoutException:\n",
    "            raise NoSuchElementException(f\"Element with xpath '{xpath}' not found\")\n",
    "        \n",
    "        #can move if run-through containing xpaths works \n",
    "        #wait = WebDriverWait(driver, 10)\n",
    "        #element = wait.until(EC.element_to_be_clickable((By.XPATH, xpath))) \n",
    "        #self.driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "        #element.click()\n",
    "\n",
    "    def _send_keys_from_xpath(self, xpath, keys):\n",
    "        wait = WebDriverWait(self.driver, self.timeout)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.XPATH, xpath))) \n",
    "        self.driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "        element.send_keys(keys)\n",
    "\n",
    "    def _click_from_css(self, css_selector):\n",
    "        try:\n",
    "            element = WebDriverWait(self.driver, self.timeout).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector))\n",
    "            )\n",
    "            element.click()\n",
    "        except TimeoutException:\n",
    "            raise NoSuchElementException(f\"Element with selector '{css_selector}' not found\")\n",
    "\n",
    "       \n",
    "    def _send_keys_from_css(self, css_selector, keys):\n",
    "        element = WebDriverWait(self.driver, self.timeout).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, css_selector))\n",
    "        )\n",
    "        element.send_keys(keys)\n",
    "\n",
    "    def open_timeline(self):\n",
    "        timeline_button = '#podfiltersbuttondatestr-news' # this is CSS selector\n",
    "        self._click_from_css(timeline_button)\n",
    "        time.sleep(10)\n",
    "        # instead try with XPath\n",
    "        #wait = WebDriverWait(driver, 10)\n",
    "        #timeline_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"/html/body/main/div/main/ln-gns-resultslist/div[2]/div/div[1]/div[1]/div[2]/div/aside/button[2]\")))\n",
    "        #timeline_button.click()\n",
    "        #time.sleep(5)\n",
    "\n",
    "    def parse_date(self, date_string):\n",
    "        date_formats = [\n",
    "            '%m/%d/%y',  # 8/1/08\n",
    "            '%m/%d/%Y',  # 8/1/2008\n",
    "            '%Y-%m-%d',  # 2008-08-01\n",
    "            '%d-%m-%Y',  # 01-08-2008\n",
    "            '%Y/%m/%d',  # 2008/08/01\n",
    "            # Add more formats as needed\n",
    "        ]\n",
    "        \n",
    "        for date_format in date_formats:\n",
    "            try:\n",
    "                return datetime.strptime(date_string, date_format)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        # If no format worked, raise an error\n",
    "        raise ValueError(f\"Unable to parse date string: {date_string}\")\n",
    "        # this would be a good place to add an exception\n",
    "        #and then maybe add in a skip/break of the loop, move to next index #\n",
    "    \n",
    "    def set_date_range(self, index):\n",
    "\n",
    "        #START_DATE AND END_DATE get established here\n",
    "        row = self.status_data.index.get_loc(index)\n",
    "        start_date_column = self.status_data.columns.get_loc('start_date')\n",
    "        end_date_column = self.status_data.columns.get_loc('end_date')\n",
    "\n",
    "        self.start_date_raw = self.status_data.iloc[row, start_date_column]\n",
    "        self.end_date_raw = self.status_data.iloc[row, end_date_column]\n",
    "\n",
    "        try:\n",
    "            start_date_str = self.parse_date(self.start_date_raw)\n",
    "            end_date_str = self.parse_date(self.end_date_raw)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error parsing dates for index {index}: {e}\")\n",
    "            return\n",
    "\n",
    "        self.start_date = start_date_str.strftime('%m/%d/%Y')\n",
    "        self.end_date = end_date_str.strftime('%m/%d/%Y')\n",
    "\n",
    "        print(f\"Setting the date range from {self.start_date} to {self.end_date}\")\n",
    "        time.sleep(1)\n",
    "              \n",
    "        # these are css selectors\n",
    "        #min_date_field = '#refine > div.supplemental.timeline > div.date-form > div.min-picker > input'\n",
    "        #max_date_field = '#refine > div.supplemental.timeline > div.date-form > div.max-picker > input'\n",
    "        \n",
    "        # trying again with xpaths instead of css selector\n",
    "        self.min_date_field = \"//input[@class='min-val' and @aria-label='Input Min Date']\"\n",
    "        self.max_date_field = \"//input[@class='max-val' and @aria-label='Input Max Date']\"\n",
    "\n",
    "        # need to include error handling for when timeline freezes, see what David did\n",
    "        \n",
    "\n",
    "        try:\n",
    "            self._click_from_xpath(self.min_date_field)\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            print('timeline closed or frozen')\n",
    "            self.open_timeline()\n",
    "            time.sleep(5)\n",
    "            #driver.refresh() # does that work? or:\n",
    "            #search_link = driver.current_url\n",
    "            #driver.get(search_link) # ??? or:\n",
    "            #driver.execute_script(\"location.reload()\")\n",
    "            # if after five tries, still no timeline, reset login information\n",
    "\n",
    "        # Clear out the default min date\n",
    "        #self._click_from_css(min_date_field)\n",
    "        time.sleep(5)\n",
    "        self.select_all = Keys.COMMAND, \"a\"\n",
    "        #self._send_keys_from_css(min_date_field, select_all); \n",
    "\n",
    "        # try with xpath\n",
    "        self._send_keys_from_xpath(self.min_date_field, self.select_all); \n",
    "        # Put the new min date in \n",
    "        self._send_keys_from_xpath(self.min_date_field, self.start_date)\n",
    "        print (f\"Min date set to {self.start_date}\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Clear out the default max date \n",
    "        self._send_keys_from_xpath(self.max_date_field, self.select_all); \n",
    "        # Put the new max date in \n",
    "        self._send_keys_from_xpath(self.max_date_field, self.end_date)\n",
    "        print (f\"Max date set to {self.end_date}\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        timeline_ok_button = '#refine > div.supplemental.timeline > div.date-form > button'\n",
    "\n",
    "        try:\n",
    "            self._click_from_css(timeline_ok_button)\n",
    "            time.sleep(10) \n",
    "        except NoSuchElementException:\n",
    "            self.driver.refresh()\n",
    "            print (f\"resetting dates to default\")\n",
    "            raise SingleResultException\n",
    "        \n",
    "\n",
    "    def timeline_reset(self):\n",
    "        timeline_reset_button = '#sidebar > div.search-controls > div.filter-container.filterpanel-target > ul > li:nth-child(2) > button > span'\n",
    "        try:\n",
    "            self._click_from_css(timeline_reset_button)\n",
    "            print(\"Cleared previous timeline filter\")\n",
    "            time.sleep(10)\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            print(\"Default time filter\")\n",
    "            self.open_timeline()\n",
    "\n",
    "    ''' \n",
    "    # commenting out because I think we'll set date range every row \n",
    "\n",
    "    def timeline_by_type(self, index): #change this name eventually\n",
    "\n",
    "        #row = self.status_data.index.get_loc(index)\n",
    "        row = self.status_data.iloc[index] #  this\n",
    "        self.set_date = row['set_date']\n",
    "        \n",
    "        if self.download_type == 'excel':\n",
    "\n",
    "            self.timeline_reset()\n",
    "            print(\"Opening timeline\")\n",
    "            self.set_date_range(index)\n",
    "\n",
    "        else: # don't need to clear timeline filter for pdf unless set_date is 1\n",
    "\n",
    "            #   click clear_timeline # or whatever\n",
    "            if self.set_date == 1:\n",
    "\n",
    "                self.timeline_reset()\n",
    "                self.set_date_range(index)\n",
    "\n",
    "                # and then reset the timeline\n",
    "\n",
    "            else:\n",
    "                # if there is already timelie filter, pass\n",
    "                pass # or continue?\n",
    "    '''\n",
    "\n",
    "    def group_duplicates(self):\n",
    "        actions_dropdown_xpath = \"//button[@id='resultlistactionmenubuttonhc-yk' and text()='Actions']\"\n",
    "        time.sleep(5)\n",
    "        self._click_from_xpath(actions_dropdown_xpath)\n",
    "        time.sleep(5)\n",
    "        moderate_button = \"//button[contains(@class, 'action') and @data-action='changeduplicates' and @data-value='moderate']\"\n",
    "        self._click_from_xpath(moderate_button)\n",
    "        print(\"group duplicate results by moderate similarity\")\n",
    "        time.sleep(10)\n",
    "    \n",
    "    def sort_by_date(self):\n",
    "        sortby_dropdown_css = '#select'\n",
    "        oldestnewest_option_text = 'Date (oldest-newest)'\n",
    "            \n",
    "        def handle_popup():\n",
    "            analytics_popup = \"//button[@class='_pendo-close-guide' and @aria-label='Close' and contains(@id, 'pendo-close-guide')]\"\n",
    "            try:\n",
    "                popup_element = WebDriverWait(self.driver, 5).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, analytics_popup))\n",
    "                )\n",
    "                popup_element.click()\n",
    "                print(\"Popup closed\")\n",
    "                time.sleep(2)\n",
    "            except TimeoutException:\n",
    "                print(\"No popup found\") \n",
    "\n",
    "        for attempt in range(3):  # Try up to 3 times\n",
    "            try:\n",
    "                # Check for and close popup before interacting with dropdown\n",
    "                handle_popup()\n",
    "\n",
    "                # Wait for the dropdown to be clickable\n",
    "                dropdown = WebDriverWait(self.driver, 20).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, sortby_dropdown_css))\n",
    "                )\n",
    "                \n",
    "                # Use Select class to interact with the dropdown\n",
    "                select = Select(dropdown)\n",
    "                select.select_by_visible_text(oldestnewest_option_text)\n",
    "                \n",
    "                print(\"Selected 'Date (oldest-newest)' option\")\n",
    "                time.sleep(5)  # Wait for the page to update\n",
    "                return  # Success, exit the function\n",
    "                \n",
    "            except StaleElementReferenceException:\n",
    "                print(\"Stale element, retrying...\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "                \n",
    "            except (TimeoutException, NoSuchElementException):\n",
    "                print(f\"Attempt {attempt + 1}: Can't find sort-by dropdown, refreshing the page\")\n",
    "                self.driver.refresh()\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "                \n",
    "            except ElementClickInterceptedException:\n",
    "                print(\"Popup is in the way, attempting to close it\")\n",
    "                handle_popup()\n",
    "                continue\n",
    "                \n",
    "            except ElementNotInteractableException:\n",
    "                print(\"Element not interactable, attempting to close popup if present\")\n",
    "                handle_popup()\n",
    "                continue\n",
    "        \n",
    "        print(\"Failed to sort by date after multiple attempts\")\n",
    "\n",
    "    def DownloadSetup(self):\n",
    "        self.group_duplicates()\n",
    "        self.sort_by_date()\n",
    "\n",
    "    def get_result_count(self, index, max_attempts=3):\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                # Wait for the element to be present\n",
    "                count_element = WebDriverWait(self.driver, self.timeout).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"#sidebar > div.search-controls > div.content-type-container.isBisNexisRedesign > ul > li.active\"))\n",
    "                )\n",
    "                \n",
    "                # Wait for the attribute to be non-empty\n",
    "                WebDriverWait(self.driver, self.timeout).until(\n",
    "                    lambda d: count_element.get_attribute(\"data-actualresultscount\") != \"\"\n",
    "                )\n",
    "                \n",
    "                result_count_element = count_element.get_attribute(\"data-actualresultscount\")\n",
    "                self.result_count = int(result_count_element)\n",
    "                return self.result_count\n",
    "\n",
    "            except TypeError:\n",
    "                print(\"Result count type error, waiting 20s for count to appear\")\n",
    "                time.sleep(20)\n",
    "                continue\n",
    "\n",
    "            except (TimeoutException, NoSuchElementException, StaleElementReferenceException) as e:\n",
    "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt < max_attempts - 1:\n",
    "                    print(\"Refreshing page and retrying...\")\n",
    "                    self.driver.refresh()\n",
    "                    time.sleep(5)  # Wait for page to reload\n",
    "                else:\n",
    "                    print(\"Max attempts reached. Could not retrieve result count.\")\n",
    "                    if download_type == 'excel':\n",
    "                        self.status_data.loc[index, 'basin_count'] = None\n",
    "                    else:\n",
    "                        self.status_data.loc[index, 'total_count'] = None\n",
    "                    self.status_data.to_csv(self.status_file)\n",
    "                    return None\n",
    "\n",
    "            except ValueError as e:\n",
    "                print(f\"Error converting result count to integer: {str(e)}\")\n",
    "                if download_type == 'excel':\n",
    "                    self.status_data.loc[index, 'basin_count'] = None\n",
    "                else:\n",
    "                    self.status_data.loc[index, 'total_count'] = None\n",
    "                self.status_data.to_csv(self.status_file)\n",
    "                return None\n",
    "                \n",
    "    def result_count_to_df(self, index):\n",
    "               \n",
    "        if self.download_type == 'excel':\n",
    "            # Update status data and return result\n",
    "            self.status_data.loc[index, 'basin_count'] = self.result_count\n",
    "            self.status_data.to_csv(self.status_file)\n",
    "            print(f\"row {index} updated with {self.result_count} results in date range\")\n",
    "            return self.result_count\n",
    "\n",
    "        else: #if self.download_type == 'pdf':\n",
    "            self.start_count = self.status_data.loc[index, 'start_count']\n",
    "            self.stop_count = self.status_data.loc[index, 'stop_count']\n",
    "\n",
    "            # if the range of results exceeds results to be downloaded in this row\n",
    "            if self.result_count > self.stop_count:\n",
    "                self.file_count = int((self.stop_count - self.start_count) + 1)\n",
    "                self.status_data.loc[index, 'total_count'] = self.file_count\n",
    "                print(f\"row {index} updated with {self.file_count} results to be downloaded\")\n",
    "                self.status_data.to_csv(self.status_file)\n",
    "                \n",
    "            else: # if the results end in this row\n",
    "                # update end count\n",
    "                self.file_count = int((self.result_count - self.start_count) + 1)\n",
    "                self.status_data.loc[index, 'total_count'] = self.file_count\n",
    "                #self.status_data.loc[index, 'stop_count'] = self.result_count\n",
    "                print(f\"row {index} updated with {self.file_count} results to be downloaded\")\n",
    "                self.status_data.to_csv(self.status_file)\n",
    "\n",
    "                if self.result_count < 501:\n",
    "                    self.next_row = index + 1\n",
    "                    print(f\"row {index} includes all results in date range\")\n",
    "                    print(f\"updating row {self.next_row} status to automatically skip\")\n",
    "                    self.status_data.loc[self.next_row, 'total_count'] = 0\n",
    "                    self.status_data.loc[self.next_row, 'finished'] = 1\n",
    "                    #self.status_data.loc[next_row, 'start_count'] = 0\n",
    "                    #self.status_data.loc[next_row, 'stop_count'] = 0\n",
    "                    self.status_data.to_csv(self.status_file)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "    def result_count_handling(self, index):\n",
    "\n",
    "        if self.result_count < 1000:\n",
    "            self.result_count_to_df(index)        \n",
    "\n",
    "        else:\n",
    "            # If result count is 1000 or more, check one more time\n",
    "            print(\"Result count is 1000 or more. Checking again...\")\n",
    "            time.sleep(5)  # Wait a bit before checking again\n",
    "            \n",
    "            # Repeat the process to get the count again\n",
    "            count_element = WebDriverWait(self.driver, self.timeout).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"#sidebar > div.search-controls > div.content-type-container.isBisNexisRedesign > ul > li.active\"))\n",
    "            )\n",
    "            result_count_element = count_element.get_attribute(\"data-actualresultscount\")\n",
    "            self.result_count = int(result_count_element)\n",
    "            print(f\"Second check result count for row {index} is {self.result_count}\")\n",
    "\n",
    "            if self.result_count < 1000:\n",
    "                self.result_count_to_df(index) \n",
    "\n",
    "            else:\n",
    "                self.DateFilter(index)    \n",
    "                time.sleep(5)\n",
    "                \n",
    "                if self.result_count < 1000:\n",
    "                    self.result_count_to_df(index) \n",
    "                else:\n",
    "                    # If still 1000 or more, update status data and raise SkipRowException\n",
    "                    if download_type == 'excel':\n",
    "                        self.status_data.loc[index, 'basin_count'] = self.result_count\n",
    "                    else:\n",
    "                        self.status_data.loc[index, 'total_count'] = self.result_count\n",
    "                    self.status_data.loc[index, 'over_one_thousand'] = 1\n",
    "                    self.status_data.to_csv(self.status_file)\n",
    "                    raise SkipRowException(f\"Result count is still {self.result_count} after third check.\")\n",
    "\n",
    "    # this portion deals with if the downloads in login session exceed 1000 cumulatively\n",
    "    # but I'm actually going to comment it out because idk it's working fine without tally\n",
    "    '''\n",
    "    def tally_result_count(self, index):\n",
    "        current_count = self.get_result_count(index)\n",
    "        self.result_tally += current_count\n",
    "        time.sleep(3)\n",
    "       \n",
    "        if self.result_tally >= 1000:\n",
    "            print(\"exceeded 1000 results downloaded, need to reset StoredLoginInformation\")\n",
    "            time.sleep(30)\n",
    "            self.reset(index) # maybe??\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "            '''\n",
    "\n",
    "    def DateFilter(self, index):\n",
    "\n",
    "        if self.download_type == 'excel':\n",
    "\n",
    "            self.timeline_reset()\n",
    "            print(\"Opening timeline\")\n",
    "            self.set_date_range(index)\n",
    "\n",
    "        else: # don't need to clear timeline filter for pdf unless set_date is 1\n",
    "\n",
    "            set_date = self.status_data.loc[index, 'set_date']\n",
    "            if set_date == 1:\n",
    "\n",
    "                self.timeline_reset()\n",
    "                self.set_date_range(index)\n",
    "\n",
    "                # and then reset the timeline\n",
    "\n",
    "            else:\n",
    "                # if there is already timeline filter, pass\n",
    "                pass # or continue?\n",
    "\n",
    "        try:\n",
    "            self.get_result_count(index)\n",
    "            self.result_count_handling(index)\n",
    "        except SkipRowException:\n",
    "            raise\n",
    "            #end the loop, go to next one\n",
    "            # though I might change this for pdf process so it knows to skip the rest until set_date ==1\n",
    "        #self.tally_result_count(index) #and this method is commented out at the moment\n",
    "    \n",
    "    def ExcelSegments(self):\n",
    "        # we just want headline, summary, publication, date\n",
    "        self.checkboxes = self.driver.find_elements(By.CSS_SELECTOR, 'input[type=\"checkbox\"]')\n",
    "        self.keep_checked_ids = ['HEA', 'PUB', 'PDT'] # headline, publication, published date\n",
    "        # Scroll into view and uncheck each checkbox if it is checked\n",
    "        for checkbox in self.checkboxes:\n",
    "            id = checkbox.get_attribute('id')\n",
    "            try:    \n",
    "                if checkbox.is_selected() and id not in self.keep_checked_ids:\n",
    "                    ActionChains(self.driver).move_to_element(checkbox).perform()\n",
    "                    checkbox.click()\n",
    "            except Exception as e:\n",
    "                #print(f\"Error processing checkboxes: {e}\")\n",
    "                #print(f\"Error processing checkboxes\") # terminal looks messy printing the whole error but I can keep this if necessary\n",
    "                pass\n",
    "        print(\"unchecked unnecessary columns\")\n",
    "\n",
    "    def get_filename(self, index):\n",
    "        if self.download_type == 'excel':\n",
    "            self.filename = f'ResultsList_{self.basin_code}_index{index}'\n",
    "            return self.filename\n",
    "        else:\n",
    "            self.filename = f'FullText_{self.basin_code}_index{index}'\n",
    "            return self.filename\n",
    "        \n",
    "    def excelDownloadOptions(self):\n",
    "    \n",
    "        results_list_option = WebDriverWait(self.driver, 10).until(EC.element_to_be_clickable\n",
    "                            ((By.XPATH, \"//input[@type='radio' and @id='ResultsListOnly']\")))\n",
    "        results_list_option.click()\n",
    "        print(\"choose resultslist download type\")\n",
    "        \n",
    "        #self.result_list_field = '#SelectedRange' #css\n",
    "        #self.result_list_field = '//*[@id=\"SelectedRange\"]' #xpath copied\n",
    "        #self.result_list_field = \"//input[@type='text' and @id='SelectedRange']\" #xpath my guess\n",
    "\n",
    "        try:\n",
    "            self.result_range_string = f\"1-{self.result_count}\"\n",
    "            print(f\"Results {self.result_range_string}\")\n",
    "            time.sleep(2)\n",
    "        except SingleResultException:\n",
    "            self.result_range_string = f\"{self.result_count}\"\n",
    "            print(f\"Only one result to download\")\n",
    "            time.sleep(2)\n",
    "\n",
    "        # put in results count to download\n",
    "        self._send_keys_from_xpath(self.result_range_field, self.result_range_string)\n",
    "        \n",
    "        self.filetype_excel_option = \"//input[@type='radio' and @id='XLSX']\"\n",
    "        print(\"choose excel option\")\n",
    "        self._click_from_xpath(self.filetype_excel_option)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # un-select unnecessary columns\n",
    "        self.ExcelSegments()\n",
    "        time.sleep(2)\n",
    "\n",
    "    def pdfDownloadOptions(self, index):\n",
    "            #status_data... unless it's defined outside the class??\n",
    "            #self.start_count = self.status_data.loc[index, 'start_count']\n",
    "            #self.stop_count = self.status_data.loc[index, 'stop_count']\n",
    "            try:\n",
    "                self.result_range_string = f\"{self.start_count}-{self.file_count}\"\n",
    "                print(f\"Results {self.result_range_string}\")\n",
    "                time.sleep(2)\n",
    "            except SingleResultException:\n",
    "                self.result_range_string = f\"{self.result_count}\"\n",
    "                print(f\"Only one result to download\")\n",
    "                time.sleep(2)\n",
    "\n",
    "            MSWord_option = \"//input[@type= 'radio' and @id= 'Docx']\"\n",
    "            self._click_from_xpath(MSWord_option)\n",
    "\n",
    "            separate_files_option = \"//input[@type= 'radio' and @id= 'SeparateFiles']\"\n",
    "            self._click_from_xpath(separate_files_option)\n",
    "\n",
    "            #zip_option = \"//input[@type= 'checkbox' and @id= 'ZipFile']\"\n",
    "            #self._click_from_xpath(zip_option) # it's selected by default when saving individual files\n",
    "            time.sleep(2)\n",
    "\n",
    "            self._send_keys_from_xpath(self.result_range_field, self.result_range_string)\n",
    "            time.sleep(2)\n",
    "\n",
    "    def DownloadDialog(self, index):\n",
    "        open_download_options = \"//button[@class='has_tooltip' and @data-action='downloadopt']\"\n",
    "        self._click_from_xpath(open_download_options)\n",
    "        time.sleep(5) \n",
    "\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Wait for the element to be clickable\n",
    "                self.result_range_field = \"//input[@id='SelectedRange']\"\n",
    "                \n",
    "                # <input type=\"text\" id=\"SelectedRange\" name=\"SelectedRange\" class=\"\" placeholder=\"Enter one or more row ranges to export.\">\n",
    "\n",
    "                # check if we're in the dialog box by looking for clickable field button\n",
    "                WebDriverWait(self.driver, 10).until(EC.element_to_be_clickable((By.XPATH, self.result_range_field)))\n",
    "                                                     \n",
    "                break  # Exit the loop if successful\n",
    "\n",
    "                # can i change this to like\n",
    "                #if results_list_option:\n",
    "                #   results_list_option.click()\n",
    "\n",
    "            except (NoSuchElementException, TimeoutException):\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Attempt {attempt + 1} failed to open download window, retrying in 10 seconds\")\n",
    "                    time.sleep(10)\n",
    "                    self._click_from_xpath(open_download_options)  # Try opening the download options again\n",
    "                    time.sleep(5)\n",
    "                else:\n",
    "                    print(\"download limit banner appeared, need to reset login\")\n",
    "                    self.reset_needed = True\n",
    "                    raise ResetRequiredException()\n",
    "\n",
    "        if self.download_type == 'excel':\n",
    "            self.excelDownloadOptions(index)\n",
    "\n",
    "        else:\n",
    "            self.pdfDownloadOptions(index)\n",
    "        \n",
    "        # rename file name\n",
    "        self.filename_field = \"//input[@type='text' and @id='FileName']\"\n",
    "        self._send_keys_from_xpath(self.filename_field, (Keys.COMMAND, \"a\"))\n",
    "        self.filename = self.get_filename(index)\n",
    "        print(f'changing filename to {self.filename}')\n",
    "        self._send_keys_from_xpath(self.filename_field, self.filename)\n",
    "\n",
    "    def click_download(self, index):\n",
    "        self.download_button = \"//button[@type='submit' and @class='button primary' and @data-action='download']\"\n",
    "\n",
    "        try:\n",
    "            self._click_from_xpath(self.download_button)\n",
    "            print(f\"downloading {self.filename}\")\n",
    "            time.sleep(10)\n",
    "            \n",
    "            # Wait for and confirm download\n",
    "            if not self.wait_for_download():\n",
    "                print(f\"Download failed for index {index}\")\n",
    "                return False\n",
    "\n",
    "            # Move file to correct location\n",
    "            if not self.move_file(index):\n",
    "                print(f\"Failed to move file for index {index}\")\n",
    "                return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing download for index {index}: {str(e)}\")\n",
    "            return False\n",
    "        # click download\n",
    "        \n",
    "\n",
    "        #self.result_count = self.get_result_count(index)       \n",
    "\n",
    "    def wait_for_download(self):\n",
    "        try:\n",
    "            # First, wait for UI indication that download started\n",
    "            print(\"Waiting for download to start...\")\n",
    "            WebDriverWait(self.driver, 60).until(\n",
    "                EC.presence_of_element_located((By.ID, \"delivery-popin\"))\n",
    "            )\n",
    "            print(\"Download started, processing...\")\n",
    "            \n",
    "            # Wait for UI indication that browser finished\n",
    "            WebDriverWait(self.driver, 120).until_not(\n",
    "                EC.presence_of_element_located((By.ID, \"delivery-popin\"))\n",
    "            )\n",
    "            print(\"Browser reports download complete!\")\n",
    "\n",
    "            # Confirm file exists\n",
    "            self.download_manager.wait_for_download(timeout=30)\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            if \"presence_of_element_located\" in str(e):\n",
    "                print(\"Download popup never appeared\")\n",
    "            else:\n",
    "                print(\"Download didn't complete within the timeout period\")\n",
    "            return False\n",
    "\n",
    "    def move_file(self, index):\n",
    "        filename = self.get_filename(index)  # Your existing filename generation\n",
    "        destination_path = f\"{self.download_folder}/{filename}.ZIP\"\n",
    "        \n",
    "        max_attempts = 3\n",
    "        attempts = 0\n",
    "        \n",
    "        while attempts < max_attempts:\n",
    "            try:\n",
    "                self.download_manager.move_latest_download(destination_path)\n",
    "                print(f\"File moved to {self.basin_code} folder\")\n",
    "                time.sleep(2)\n",
    "                return True\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found on attempt {attempts + 1}\")\n",
    "                time.sleep(10)\n",
    "                attempts += 1\n",
    "        \n",
    "        try:\n",
    "            self.driver.refresh()\n",
    "            time.sleep(5)\n",
    "            self.download_manager.move_latest_download(destination_path)\n",
    "            print(f\"File moved to {self.basin_code} folder after refresh\")\n",
    "            return True\n",
    "        except FileNotFoundError:\n",
    "            print(\"File missing or not moved\")\n",
    "            return False\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Call this when done with all downloads\"\"\"\n",
    "        if hasattr(self, 'download_manager'):\n",
    "            self.download_manager.cleanup()\n",
    "\n",
    "\n",
    "    def update_status(self, index):\n",
    "        self.filename = self.get_filename(index)\n",
    "        self.downloaded_file = self.filename + \".ZIP\"\n",
    "        #self.result_count = self.get_result_count(index)\n",
    "        #filename_column\n",
    "        #finished_column\n",
    "        \n",
    "        downloaded_file_path = os.path.join(self.download_folder, self.downloaded_file)\n",
    "        file_exists = os.path.isfile(downloaded_file_path)\n",
    "\n",
    "        if file_exists:\n",
    "            self.status_data.loc[index, 'file_name'] = str(self.filename)\n",
    "            self.status_data.loc[index, 'finished'] = 1\n",
    "            self.status_data.to_csv(self.status_file)\n",
    "            print(f\"status sheet row {index} updated\")\n",
    "        else:\n",
    "            self.status_data.loc[index, 'finished'] = 0\n",
    "            print(f\"row {index} not marked as finished\")\n",
    "\n",
    "    def file_handling(self, index):\n",
    "        self.move_file(index)\n",
    "        self.update_status(index)\n",
    "\n",
    "    def DownloadProcess(self, index):\n",
    "        self.DateFilter(index)\n",
    "        try:\n",
    "            self.DownloadDialog(index) # i had these indented too... the logic was that these don't need to happen if reset  \n",
    "            download_success = self.wait_for_download()\n",
    "            if download_success:\n",
    "                self.file_handling(index)\n",
    "        except SkipRowException:\n",
    "            raise\n",
    "        except ResetRequiredException:\n",
    "            raise\n",
    "        # there might be another exception to add here...\n",
    "\n",
    "# now this part\n",
    "\n",
    "    def main(self, index, basin_code): # why am I not calling index?\n",
    "        print(f\"Download for {basin_code}\")\n",
    "        self.DownloadSetup()  # sort by date and group duplicates before date filtering\n",
    "        \n",
    "        row_index = 0\n",
    "        try:\n",
    "            while row_index < len(self.status_data):\n",
    "\n",
    "                # Check if all rows are finished\n",
    "                if (self.status_data['finished'] == 1).all():\n",
    "                    print(f\"All rows for {basin_code} are downloaded!\")\n",
    "                    #if self.download_type == \"excel\": # oh is download type not here yet?\n",
    "                        #combine_excel = CombineResults(basin_code)\n",
    "                        #combine_excel.combine()\n",
    "                    #else:\n",
    "                    #pass\n",
    "                    break\n",
    "\n",
    "                row = self.status_data.iloc[row_index] #why is this diff than index?\n",
    "                self.finished = row['finished']\n",
    "                self.over_thousand = row['over_one_thousand']\n",
    "\n",
    "                if self.finished != 1 and self.over_thousand != 1:\n",
    "                    try:\n",
    "                        print(f\"Proceeding to download basin {basin_code} row {row_index}\")\n",
    "                        time.sleep(1)\n",
    "                        self.current_row = row\n",
    "                        self.DownloadProcess(row_index)\n",
    "                        row_index += 1  # Move to next row only if successful\n",
    "                    except SkipRowException:    \n",
    "                        print(f\"row {row_index} result count exceeds 1000, skipping to next row\")\n",
    "                        self.status_data.at[row_index, 'over_one_thousand'] = 1  # Update status\n",
    "                        row_index += 1  # Move to next row\n",
    "                    except ResetRequiredException:\n",
    "                        if self.reset_needed:\n",
    "                            self.reset()\n",
    "                            self.reset_needed = False\n",
    "                            time.sleep(1)\n",
    "                            print(f\"Restarting download process at row {row_index}\")\n",
    "                            # Don't increment row_index, will retry the same row\n",
    "                else:\n",
    "                    row_index += 1  # Move to next row if finished or over thousand\n",
    "        finally:\n",
    "            self.cleanup()\n",
    "\n",
    "    def reset(self):\n",
    "        sign_in_button = \"//button[@id='SignInRegisterBisNexis']\"\n",
    "        self._click_from_xpath(sign_in_button)\n",
    "        print(\"logging out\")\n",
    "        self.driver.delete_all_cookies()\n",
    "        print(\"deleting cookies before logging in again\")\n",
    "        time.sleep(3)\n",
    "        self.login._init_login()\n",
    "        self.nlc._search_process()\n",
    "        time.sleep(5)\n",
    "        self.DownloadSetup()\n",
    "\n",
    "download = Download(\n",
    "            driver=driver,\n",
    "            basin_code=basin_code,\n",
    "            user_name=user_name,\n",
    "            index=0,  \n",
    "            login = login,\n",
    "            nlc = nlc,\n",
    "            download_type = download_type,\n",
    "            download_folder = download_folder,\n",
    "            download_folder_temp = download_folder_temp,\n",
    "            status_file=status_file,\n",
    "            finished=False,  \n",
    "            url=None,  \n",
    "            timeout=20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for Files (273).ZIP in default downloads folder\n",
      "file in tigr download folder\n",
      "status sheet row 8 updated\n"
     ]
    }
   ],
   "source": [
    "download.file_handling(index=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download for tigr\n",
      "Proceeding to download basin tigr row 10\n",
      "Cleared previous timeline filter\n",
      "Setting the date range from 07/01/2013 to 06/30/2014\n",
      "Min date set to 07/01/2013\n",
      "Max date set to 06/30/2014\n",
      "Results 1-370\n",
      "changing filename to FullText_tigr_index10\n",
      "downloading FullText_tigr_index10\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Download complete!\n",
      "looking for Files (370).ZIP in default downloads folder\n",
      "file in tigr download folder\n",
      "status sheet row 10 updated\n",
      "Proceeding to download basin tigr row 12\n",
      "Cleared previous timeline filter\n",
      "Setting the date range from 07/01/2014 to 06/30/2015\n",
      "Min date set to 07/01/2014\n",
      "Max date set to 06/30/2015\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 12\n",
      "Proceeding to download basin tigr row 12\n",
      "Default time filter\n",
      "Setting the date range from 07/01/2014 to 06/30/2015\n",
      "Min date set to 07/01/2014\n",
      "Max date set to 06/30/2015\n",
      "Results 1-500\n",
      "changing filename to FullText_tigr_index12\n",
      "downloading FullText_tigr_index12\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Error: Message: \n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Proceeding to download basin tigr row 13\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 13\n",
      "Proceeding to download basin tigr row 13\n",
      "Result count is 1000 or more. Checking again...\n",
      "Second check result count for row 13 is 20039\n",
      "row 13 result count exceeds 1000, skipping to next row\n",
      "Proceeding to download basin tigr row 14\n",
      "Default time filter\n",
      "Setting the date range from 07/01/2015 to 06/30/2016\n",
      "Min date set to 07/01/2015\n",
      "Max date set to 06/30/2016\n",
      "Result count type error, waiting 20s for count to appear\n",
      "Results 1-500\n",
      "changing filename to FullText_tigr_index14\n",
      "downloading FullText_tigr_index14\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Error: Message: \n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Proceeding to download basin tigr row 15\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 15\n",
      "Proceeding to download basin tigr row 15\n",
      "Result count is 1000 or more. Checking again...\n",
      "Second check result count for row 15 is 20039\n",
      "row 15 result count exceeds 1000, skipping to next row\n",
      "Proceeding to download basin tigr row 16\n",
      "Default time filter\n",
      "Setting the date range from 07/01/2016 to 12/31/2016\n",
      "Min date set to 07/01/2016\n",
      "Max date set to 12/31/2016\n",
      "Results 1-500\n",
      "changing filename to FullText_tigr_index16\n",
      "downloading FullText_tigr_index16\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Error: Message: \n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Proceeding to download basin tigr row 17\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 17\n",
      "Proceeding to download basin tigr row 17\n",
      "Result count is 1000 or more. Checking again...\n",
      "Second check result count for row 17 is 20039\n",
      "row 17 result count exceeds 1000, skipping to next row\n",
      "Proceeding to download basin tigr row 18\n",
      "Default time filter\n",
      "Setting the date range from 01/01/2017 to 04/30/2017\n",
      "Min date set to 01/01/2017\n",
      "Max date set to 04/30/2017\n",
      "Results 1-500\n",
      "changing filename to FullText_tigr_index18\n",
      "downloading FullText_tigr_index18\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Error: Message: \n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Proceeding to download basin tigr row 19\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 19\n",
      "Proceeding to download basin tigr row 19\n",
      "Result count is 1000 or more. Checking again...\n",
      "Second check result count for row 19 is 20039\n",
      "row 19 result count exceeds 1000, skipping to next row\n",
      "Proceeding to download basin tigr row 20\n",
      "Default time filter\n",
      "Setting the date range from 05/01/2017 to 09/30/2017\n",
      "Min date set to 05/01/2017\n",
      "Max date set to 09/30/2017\n",
      "Results 1-500\n",
      "changing filename to FullText_tigr_index20\n",
      "downloading FullText_tigr_index20\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Error: Message: \n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Proceeding to download basin tigr row 21\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 21\n",
      "Proceeding to download basin tigr row 21\n",
      "Result count is 1000 or more. Checking again...\n",
      "Second check result count for row 21 is 20038\n",
      "row 21 result count exceeds 1000, skipping to next row\n",
      "Proceeding to download basin tigr row 22\n",
      "Default time filter\n",
      "Setting the date range from 10/01/2017 to 04/30/2018\n",
      "Min date set to 10/01/2017\n",
      "Max date set to 04/30/2018\n",
      "Results 1-500\n",
      "changing filename to FullText_tigr_index22\n",
      "downloading FullText_tigr_index22\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Error: Message: \n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Proceeding to download basin tigr row 23\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 23\n",
      "Proceeding to download basin tigr row 23\n",
      "Result count is 1000 or more. Checking again...\n",
      "Second check result count for row 23 is 20039\n",
      "row 23 result count exceeds 1000, skipping to next row\n",
      "Proceeding to download basin tigr row 24\n",
      "Default time filter\n",
      "Setting the date range from 05/01/2018 to 11/30/2018\n",
      "Min date set to 05/01/2018\n",
      "Max date set to 11/30/2018\n",
      "Results 1-500\n",
      "changing filename to FullText_tigr_index24\n",
      "downloading FullText_tigr_index24\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Error: Message: \n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Proceeding to download basin tigr row 25\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 25\n",
      "Proceeding to download basin tigr row 25\n",
      "Result count is 1000 or more. Checking again...\n",
      "Second check result count for row 25 is 20038\n",
      "row 25 result count exceeds 1000, skipping to next row\n",
      "Proceeding to download basin tigr row 26\n",
      "Default time filter\n",
      "Setting the date range from 12/01/2018 to 03/31/2019\n",
      "Min date set to 12/01/2018\n",
      "Max date set to 03/31/2019\n",
      "Results 1-500\n",
      "changing filename to FullText_tigr_index26\n",
      "downloading FullText_tigr_index26\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Error: Message: \n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Proceeding to download basin tigr row 27\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "had to click search button again for some reason\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 27\n",
      "Proceeding to download basin tigr row 27\n",
      "Result count is 1000 or more. Checking again...\n",
      "Second check result count for row 27 is 20038\n",
      "row 27 result count exceeds 1000, skipping to next row\n",
      "Proceeding to download basin tigr row 28\n",
      "Default time filter\n",
      "Setting the date range from 04/01/2019 to 12/31/2019\n",
      "Min date set to 04/01/2019\n",
      "Max date set to 12/31/2019\n",
      "Results 1-500\n",
      "changing filename to FullText_tigr_index28\n",
      "downloading FullText_tigr_index28\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Error: Message: \n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Proceeding to download basin tigr row 29\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 29\n",
      "Proceeding to download basin tigr row 29\n",
      "Result count is 1000 or more. Checking again...\n",
      "Second check result count for row 29 is 20038\n",
      "row 29 result count exceeds 1000, skipping to next row\n",
      "Proceeding to download basin tigr row 30\n",
      "Default time filter\n",
      "Setting the date range from 01/01/2020 to 12/31/2021\n",
      "Min date set to 01/01/2020\n",
      "Max date set to 12/31/2021\n",
      "Results 1-500\n",
      "changing filename to FullText_tigr_index30\n",
      "downloading FullText_tigr_index30\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Error: Message: \n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Proceeding to download basin tigr row 31\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "Popup closed\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 31\n",
      "Proceeding to download basin tigr row 31\n",
      "Result count is 1000 or more. Checking again...\n",
      "Second check result count for row 31 is 20039\n",
      "row 31 result count exceeds 1000, skipping to next row\n",
      "Proceeding to download basin tigr row 32\n",
      "Default time filter\n",
      "Setting the date range from 01/01/2022 to 11/30/2023\n",
      "Min date set to 01/01/2022\n",
      "Max date set to 11/30/2023\n",
      "Results 1-500\n",
      "changing filename to FullText_tigr_index32\n",
      "downloading FullText_tigr_index32\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Error: Message: \n",
      "\n",
      "Download didn't complete within the timeout period\n",
      "Proceeding to download basin tigr row 33\n",
      "Attempt 1 failed to open download window, retrying in 10 seconds\n",
      "Attempt 2 failed to open download window, retrying in 10 seconds\n",
      "download limit banner appeared, need to reset login\n",
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Restarting download process at row 33\n",
      "Proceeding to download basin tigr row 33\n",
      "Result count is 1000 or more. Checking again...\n",
      "Second check result count for row 33 is 20039\n",
      "row 33 result count exceeds 1000, skipping to next row\n",
      "Proceeding to download basin tigr row 34\n",
      "Default time filter\n",
      "Setting the date range from 12/01/2023 to 03/15/2024\n",
      "Min date set to 12/01/2023\n",
      "Max date set to 03/15/2024\n",
      "Results 1-166\n",
      "changing filename to FullText_tigr_index34\n",
      "downloading FullText_tigr_index34\n",
      "Waiting for download to start...\n",
      "Download started, processing...\n",
      "Download complete!\n",
      "looking for Files (166).ZIP in default downloads folder\n",
      "file in tigr download folder\n",
      "status sheet row 34 updated\n"
     ]
    }
   ],
   "source": [
    "download.main(index=0, basin_code=basin_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results 1-100\n",
      "changing filename to FullText_tigr_index0\n",
      "downloading FullText_tigr_index0\n"
     ]
    }
   ],
   "source": [
    "download.DownloadDialog(index =  0, download_type = download_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another possible problem,\n",
    "# in adition to the filename defaulting to like whatever\n",
    "# it also takes a bit longer for pdf to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullText_tigr_index0\n"
     ]
    }
   ],
   "source": [
    "if download_type == 'excel':\n",
    "    filename = f'ResultsList_{basin_code}_index0'\n",
    "    print(filename)\n",
    "else:\n",
    "    filename = f'FullText_{basin_code}_index0'\n",
    "    print (filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing filename to FullText_tigr_index0\n"
     ]
    }
   ],
   "source": [
    "filename_field = \"//input[@type='text' and @id='FileName']\"\n",
    "download._send_keys_from_xpath(filename_field, (Keys.COMMAND, \"a\"))\n",
    "filename = download.get_filename(index=0, download_type='pdf')\n",
    "print(f'changing filename to {filename}')\n",
    "download._send_keys_from_xpath(filename_field, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# something annoying that's happening  - changing filename isn't changing filename\n",
    "- for some reason even after changing the filename \n",
    "- look in downloads for \"File({number of results})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging out\n",
      "deleting cookies before logging in again\n",
      "User is already logged in.\n",
      "already on Nexis Uni home page\n",
      "Initializing search for tigr\n",
      "clicked search, on results page\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n"
     ]
    }
   ],
   "source": [
    "download.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file in tigr download folder\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Download.update_status() missing 1 required positional argument: 'download_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdownload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_handling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mDownload.file_handling\u001b[0;34m(self, index, download_type)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfile_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, index, download_type):\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmove_file(index, download_type)\n\u001b[0;32m--> 622\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Download.update_status() missing 1 required positional argument: 'download_type'"
     ]
    }
   ],
   "source": [
    "download.file_handling(index=0, download_type=download_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download for tigr\n",
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n",
      "Proceeding to download basin tigr row 0\n",
      "Default time filter\n",
      "Setting the date range from 06/30/2008 to 07/01/2009\n",
      "Min date set to 06/30/2008\n",
      "Max date set to 07/01/2009\n",
      "Result count for row 0 is 226\n",
      "Result count for row 0 is 226\n",
      "Result count for row 0 is 226\n",
      "Results 1-100\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Download.get_filename() missing 1 required positional argument: 'download_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mdownload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasin_code\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbasin_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mDownload.main\u001b[0;34m(self, index, basin_code)\u001b[0m\n\u001b[1;32m    647\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_row \u001b[38;5;241m=\u001b[39m row\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDownloadProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     row_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Move to next row only if successful\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SkipRowException:    \n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mDownload.DownloadProcess\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDateFilter(index)\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDownloadDialog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# i had these indented too... the logic was that these don't need to happen if reset\u001b[39;00m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_handling(index)\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SkipRowException:\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mDownload.DownloadDialog\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename_field \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//input[@type=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and @id=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFileName\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_keys_from_xpath(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename_field, (Keys\u001b[38;5;241m.\u001b[39mCOMMAND, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchanging filename to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_keys_from_xpath(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename_field, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename)\n",
      "\u001b[0;31mTypeError\u001b[0m: Download.get_filename() missing 1 required positional argument: 'download_type'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "status_data = pd.read_csv(status_file, index_col=0)\n",
    "row_index = 0\n",
    "while row_index < len(status_data):\n",
    "    # Check if all rows are finished\n",
    "    if (status_data['finished'] == 1).all():\n",
    "        print(f\"All rows for {basin_code} are downloaded!\")\n",
    "        break\n",
    "    else:\n",
    "        download.main(index=0, basin_code = basin_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download for tigr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group duplicate results by moderate similarity\n",
      "No popup found\n",
      "Selected 'Date (oldest-newest)' option\n"
     ]
    }
   ],
   "source": [
    "download.main(index=0, basin_code = basin_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# below here is the conversion process to add (it works!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "need to create pdf status sheet\n",
      "converting excel status sheet for tigr to pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selenawallace/Documents/geography/notebooks/../geography/classes/conversions/status_excel_to_pdf.py:60: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_result[\"start_date\"] = pd.to_datetime(df_result[\"start_date\"]).dt.strftime('%m/%d/%Y')\n",
      "/Users/selenawallace/Documents/geography/notebooks/../geography/classes/conversions/status_excel_to_pdf.py:61: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_result[\"end_date\"] = pd.to_datetime(df_result[\"end_date\"]).dt.strftime('%m/%d/%Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted tigr pdf status sheet\n"
     ]
    }
   ],
   "source": [
    "from geography.classes.conversions.status_excel_to_pdf import convert_pdf\n",
    "\n",
    "pdf_conversion = convert_pdf(basin_code)\n",
    "pdf_conversion.convert(basin_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- have I incorporated the excel-to-pdf conversion sheets? I think somewhere in main maybe????\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can also do this:\n",
    "    def get_filename(self, index):\n",
    "        if download_type == 'excel':\n",
    "            download_type_name = 'ResultsList'\n",
    "        else:\n",
    "            download_type_name = 'PDF_FullText'\n",
    "        self.filename = f'{download_type_name}_{self.basin_code}_index{index}'\n",
    "\n",
    "        return self.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- what's different about the pdf process? \n",
    "- * results popup\n",
    "- * date range, repeats\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
